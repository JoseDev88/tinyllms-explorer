{
  "kept": {
    "meta-llama/Llama-3.2-1B-Instruct": {
      "name": "Llama-3.2-1B-Instruct",
      "display_name": "Llama 3.2 1B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-1B": {
      "name": "Llama-3.2-1B",
      "display_name": "Llama 3.2 1B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-1B",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-3B-Instruct": {
      "name": "Llama-3.2-3B-Instruct",
      "display_name": "Llama 3.2 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct",
      "license": "llama3.2",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-3B": {
      "name": "Llama-3.2-3B",
      "display_name": "Llama 3.2 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-3B",
      "license": "llama3.2",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-Guard-3-1B": {
      "name": "Llama-Guard-3-1B",
      "display_name": "Llama Guard 3 1B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-Guard-3-1B",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8": {
      "name": "Llama-3.2-1B-Instruct-QLORA_INT4_EO8",
      "display_name": "Llama 3.2 1B Instruct QLORA INT4 EO8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8": {
      "name": "Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8",
      "display_name": "Llama 3.2 1B Instruct SpinQuant INT4 EO8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:05Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8": {
      "name": "Llama-3.2-3B-Instruct-QLORA_INT4_EO8",
      "display_name": "Llama 3.2 3B Instruct QLORA INT4 EO8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8",
      "license": "llama3.2",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8": {
      "name": "Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8",
      "display_name": "Llama 3.2 3B Instruct SpinQuant INT4 EO8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8",
      "license": "llama3.2",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "meta-llama"
      }
    },
    "meta-llama/Llama-Guard-3-1B-INT4": {
      "name": "Llama-Guard-3-1B-INT4",
      "display_name": "Llama Guard 3 1B INT4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/meta-llama/Llama-Guard-3-1B-INT4",
      "license": "llama3.2",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "meta-llama"
      }
    },
    "google/gemma-3-1b-it": {
      "name": "gemma-3-1b-it",
      "display_name": "gemma 3 1b it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-it",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-it": {
      "name": "gemma-2-2b-it",
      "display_name": "gemma 2 2b it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b": {
      "name": "gemma-2-2b",
      "display_name": "gemma 2 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-1.1-2b-it": {
      "name": "gemma-1.1-2b-it",
      "display_name": "gemma 1.1 2b it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-1.1-2b-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it": {
      "name": "gemma-2b-it",
      "display_name": "gemma 2b it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-2b": {
      "name": "gemma-2b",
      "display_name": "gemma 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:06Z",
        "org": "google"
      }
    },
    "google/gemma-3-270m": {
      "name": "gemma-3-270m",
      "display_name": "gemma 3 270m",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-270m",
      "license": "gemma",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-3-270m-it": {
      "name": "gemma-3-270m-it",
      "display_name": "gemma 3 270m it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-270m-it",
      "license": "gemma",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-3-1b-pt": {
      "name": "gemma-3-1b-pt",
      "display_name": "gemma 3 1b pt",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-pt",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-3n-E4B-it-litert-lm": {
      "name": "gemma-3n-E4B-it-litert-lm",
      "display_name": "gemma 3n E4B it litert lm",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3n-E4B-it-litert-lm",
      "license": "gemma",
      "params_b": 4.0,
      "quantizations": "int4",
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-3n-E2B-it-litert-lm": {
      "name": "gemma-3n-E2B-it-litert-lm",
      "display_name": "gemma 3n E2B it litert lm",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3n-E2B-it-litert-lm",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "int4",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/codegemma-2b": {
      "name": "codegemma-2b",
      "display_name": "codegemma 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-jpn-it": {
      "name": "gemma-2-2b-jpn-it",
      "display_name": "gemma 2 2b jpn it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-jpn-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/vaultgemma-1b": {
      "name": "vaultgemma-1b",
      "display_name": "vaultgemma 1b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/vaultgemma-1b",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/shieldgemma-2b": {
      "name": "shieldgemma-2b",
      "display_name": "shieldgemma 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/shieldgemma-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:07Z",
        "org": "google"
      }
    },
    "google/gemma-3-1b-it-qat-int4-unquantized": {
      "name": "gemma-3-1b-it-qat-int4-unquantized",
      "display_name": "gemma 3 1b it qat int4 unquantized",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-it-qat-int4-unquantized",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/recurrentgemma-2b-it": {
      "name": "recurrentgemma-2b-it",
      "display_name": "recurrentgemma 2b it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/recurrentgemma-2b-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/gemma-3-1b-it-qat-q4_0-gguf": {
      "name": "gemma-3-1b-it-qat-q4_0-gguf",
      "display_name": "gemma 3 1b it qat q4 0 gguf",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-gguf",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/txgemma-2b-predict": {
      "name": "txgemma-2b-predict",
      "display_name": "txgemma 2b predict",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/txgemma-2b-predict",
      "license": "other",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/gemma-3-1b-it-qat-q4_0-unquantized": {
      "name": "gemma-3-1b-it-qat-q4_0-unquantized",
      "display_name": "gemma 3 1b it qat q4 0 unquantized",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-it-qat-q4_0-unquantized",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/codegemma-1.1-2b": {
      "name": "codegemma-1.1-2b",
      "display_name": "codegemma 1.1 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-1.1-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:08Z",
        "org": "google"
      }
    },
    "google/recurrentgemma-2b": {
      "name": "recurrentgemma-2b",
      "display_name": "recurrentgemma 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/recurrentgemma-2b",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-3-270m-it-qat-q4_0-unquantized": {
      "name": "gemma-3-270m-it-qat-q4_0-unquantized",
      "display_name": "gemma 3 270m it qat q4 0 unquantized",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-270m-it-qat-q4_0-unquantized",
      "license": "gemma",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-3-1b-pt-qat-q4_0-gguf": {
      "name": "gemma-3-1b-pt-qat-q4_0-gguf",
      "display_name": "gemma 3 1b pt qat q4 0 gguf",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-1b-pt-qat-q4_0-gguf",
      "license": "gemma",
      "params_b": 1.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-3-270m-qat-q4_0-unquantized": {
      "name": "gemma-3-270m-qat-q4_0-unquantized",
      "display_name": "gemma 3 270m qat q4 0 unquantized",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-3-270m-qat-q4_0-unquantized",
      "license": "gemma",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-2b-aps-it": {
      "name": "gemma-2b-aps-it",
      "display_name": "gemma 2b aps it",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-aps-it",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-pytorch": {
      "name": "gemma-2b-it-pytorch",
      "display_name": "gemma 2b it pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/codegemma-2b-GGUF": {
      "name": "codegemma-2b-GGUF",
      "display_name": "codegemma 2b GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-2b-GGUF",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-2b-AWQ": {
      "name": "gemma-2b-AWQ",
      "display_name": "gemma 2b AWQ",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-AWQ",
      "license": "other",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:09Z",
        "org": "google"
      }
    },
    "google/gemma-2b-pytorch": {
      "name": "gemma-2b-pytorch",
      "display_name": "gemma 2b pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-1.1-2b-it-pytorch": {
      "name": "gemma-1.1-2b-it-pytorch",
      "display_name": "gemma 1.1 2b it pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-1.1-2b-it-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-2b-keras": {
      "name": "gemma-2b-keras",
      "display_name": "gemma 2b keras",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-keras",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/codegemma-2b-keras": {
      "name": "codegemma-2b-keras",
      "display_name": "codegemma 2b keras",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-2b-keras",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-keras": {
      "name": "gemma-2b-it-keras",
      "display_name": "gemma 2b it keras",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-keras",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-1.1-2b-it-keras": {
      "name": "gemma-1.1-2b-it-keras",
      "display_name": "gemma 1.1 2b it keras",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-1.1-2b-it-keras",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/codegemma-1.1-2b-keras": {
      "name": "codegemma-1.1-2b-keras",
      "display_name": "codegemma 1.1 2b keras",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-1.1-2b-keras",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-sfp-cpp": {
      "name": "gemma-2b-it-sfp-cpp",
      "display_name": "gemma 2b it sfp cpp",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-sfp-cpp",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/codegemma-1.1-2b-GGUF": {
      "name": "codegemma-1.1-2b-GGUF",
      "display_name": "codegemma 1.1 2b GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-1.1-2b-GGUF",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:10Z",
        "org": "google"
      }
    },
    "google/gemma-2b-cpp": {
      "name": "gemma-2b-cpp",
      "display_name": "gemma 2b cpp",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-cpp",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-cpp": {
      "name": "gemma-2b-it-cpp",
      "display_name": "gemma 2b it cpp",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-cpp",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/recurrentgemma-2b-it-flax": {
      "name": "recurrentgemma-2b-it-flax",
      "display_name": "recurrentgemma 2b it flax",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/recurrentgemma-2b-it-flax",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-2b-sfp-cpp": {
      "name": "gemma-2b-sfp-cpp",
      "display_name": "gemma 2b sfp cpp",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-sfp-cpp",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-2b-flax": {
      "name": "gemma-2b-flax",
      "display_name": "gemma 2b flax",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-flax",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-flax": {
      "name": "gemma-2b-it-flax",
      "display_name": "gemma 2b it flax",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-flax",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/codegemma-2b-pytorch": {
      "name": "codegemma-2b-pytorch",
      "display_name": "codegemma 2b pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-2b-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/recurrentgemma-2b-flax": {
      "name": "recurrentgemma-2b-flax",
      "display_name": "recurrentgemma 2b flax",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/recurrentgemma-2b-flax",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-2b-it-tflite": {
      "name": "gemma-2b-it-tflite",
      "display_name": "gemma 2b it tflite",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2b-it-tflite",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "int4,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/gemma-1.1-2b-it-tflite": {
      "name": "gemma-1.1-2b-it-tflite",
      "display_name": "gemma 1.1 2b it tflite",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-1.1-2b-it-tflite",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": "int4,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:11Z",
        "org": "google"
      }
    },
    "google/codegemma-1.1-2b-pytorch": {
      "name": "codegemma-1.1-2b-pytorch",
      "display_name": "codegemma 1.1 2b pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/codegemma-1.1-2b-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:12Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-pytorch": {
      "name": "gemma-2-2b-pytorch",
      "display_name": "gemma 2 2b pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:12Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-it-pytorch": {
      "name": "gemma-2-2b-it-pytorch",
      "display_name": "gemma 2 2b it pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-it-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:12Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-jpn-it-pytorch": {
      "name": "gemma-2-2b-jpn-it-pytorch",
      "display_name": "gemma 2 2b jpn it pytorch",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-jpn-it-pytorch",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:12Z",
        "org": "google"
      }
    },
    "google/gemma-2-2b-jpn-it-flax": {
      "name": "gemma-2-2b-jpn-it-flax",
      "display_name": "gemma 2 2b jpn it flax",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/google/gemma-2-2b-jpn-it-flax",
      "license": "gemma",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:12Z",
        "org": "google"
      }
    },
    "microsoft/VibeVoice-1.5B": {
      "name": "VibeVoice-1.5B",
      "display_name": "VibeVoice 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/VibeVoice-1.5B",
      "license": "mit",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:13Z",
        "org": "microsoft"
      }
    },
    "microsoft/bitnet-b1.58-2B-4T": {
      "name": "bitnet-b1.58-2B-4T",
      "display_name": "bitnet b1.58 2B 4T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T",
      "license": "mit",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:15Z",
        "org": "microsoft"
      }
    },
    "microsoft/bitnet-b1.58-2B-4T-gguf": {
      "name": "bitnet-b1.58-2B-4T-gguf",
      "display_name": "bitnet b1.58 2B 4T gguf",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf",
      "license": "mit",
      "params_b": 2.0,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:15Z",
        "org": "microsoft"
      }
    },
    "microsoft/bitnet-b1.58-2B-4T-bf16": {
      "name": "bitnet-b1.58-2B-4T-bf16",
      "display_name": "bitnet b1.58 2B 4T bf16",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-bf16",
      "license": "mit",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:16Z",
        "org": "microsoft"
      }
    },
    "microsoft/rho-math-1b-v0.1": {
      "name": "rho-math-1b-v0.1",
      "display_name": "rho math 1b v0.1",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/rho-math-1b-v0.1",
      "license": "mit",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:17Z",
        "org": "microsoft"
      }
    },
    "microsoft/rho-math-1b-interpreter-v0.1": {
      "name": "rho-math-1b-interpreter-v0.1",
      "display_name": "rho math 1b interpreter v0.1",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/microsoft/rho-math-1b-interpreter-v0.1",
      "license": "mit",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:17Z",
        "org": "microsoft"
      }
    },
    "Qwen/Qwen2.5-3B-Instruct": {
      "name": "Qwen2.5-3B-Instruct",
      "display_name": "Qwen2.5 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:19Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-0.6B": {
      "name": "Qwen3-0.6B",
      "display_name": "Qwen3 0.6B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-0.6B",
      "license": "apache-2.0",
      "params_b": 0.6,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-1.5B-Instruct": {
      "name": "Qwen2.5-1.5B-Instruct",
      "display_name": "Qwen2.5 1.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-Embedding-0.6B": {
      "name": "Qwen3-Embedding-0.6B",
      "display_name": "Qwen3 Embedding 0.6B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-Embedding-0.6B",
      "license": "apache-2.0",
      "params_b": 0.6,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-Instruct-2507": {
      "name": "Qwen3-4B-Instruct-2507",
      "display_name": "Qwen3 4B Instruct 2507",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-0.5B-Instruct": {
      "name": "Qwen2.5-0.5B-Instruct",
      "display_name": "Qwen2.5 0.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B": {
      "name": "Qwen3-4B",
      "display_name": "Qwen3 4B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-0.5B": {
      "name": "Qwen2.5-0.5B",
      "display_name": "Qwen2.5 0.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-1.7B": {
      "name": "Qwen3-1.7B",
      "display_name": "Qwen3 1.7B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-1.7B",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": null,
      "memory_min_gb": 4.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-Reranker-0.6B": {
      "name": "Qwen3-Reranker-0.6B",
      "display_name": "Qwen3 Reranker 0.6B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-Reranker-0.6B",
      "license": "apache-2.0",
      "params_b": 0.6,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:20Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2-1.5B-Instruct": {
      "name": "Qwen2-1.5B-Instruct",
      "display_name": "Qwen2 1.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2-1.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-Embedding-4B": {
      "name": "Qwen3-Embedding-4B",
      "display_name": "Qwen3 Embedding 4B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-Embedding-4B",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-Thinking-2507": {
      "name": "Qwen3-4B-Thinking-2507",
      "display_name": "Qwen3 4B Thinking 2507",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-Base": {
      "name": "Qwen3-4B-Base",
      "display_name": "Qwen3 4B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-Base",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-3B": {
      "name": "Qwen2.5-3B",
      "display_name": "Qwen2.5 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-3B",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2-0.5B": {
      "name": "Qwen2-0.5B",
      "display_name": "Qwen2 0.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2-0.5B",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-1.5B": {
      "name": "Qwen2.5-Coder-1.5B",
      "display_name": "Qwen2.5 Coder 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-1.7B-Base": {
      "name": "Qwen3-1.7B-Base",
      "display_name": "Qwen3 1.7B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-1.7B-Base",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": null,
      "memory_min_gb": 4.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2-0.5B-Instruct": {
      "name": "Qwen2-0.5B-Instruct",
      "display_name": "Qwen2 0.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2-0.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:21Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-1.5B": {
      "name": "Qwen2.5-1.5B",
      "display_name": "Qwen2.5 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-Thinking-2507-FP8": {
      "name": "Qwen3-4B-Thinking-2507-FP8",
      "display_name": "Qwen3 4B Thinking 2507 FP8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507-FP8",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Math-1.5B": {
      "name": "Qwen2.5-Math-1.5B",
      "display_name": "Qwen2.5 Math 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Math-1.5B",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-1.5B-Instruct": {
      "name": "Qwen2.5-Coder-1.5B-Instruct",
      "display_name": "Qwen2.5 Coder 1.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-1.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-0.6B-Base": {
      "name": "Qwen3-0.6B-Base",
      "display_name": "Qwen3 0.6B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-0.6B-Base",
      "license": "apache-2.0",
      "params_b": 0.6,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-AWQ": {
      "name": "Qwen3-4B-AWQ",
      "display_name": "Qwen3 4B AWQ",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-AWQ",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2-1.5B": {
      "name": "Qwen2-1.5B",
      "display_name": "Qwen2 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2-1.5B",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:22Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-Instruct-2507-FP8": {
      "name": "Qwen3-4B-Instruct-2507-FP8",
      "display_name": "Qwen3 4B Instruct 2507 FP8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-Instruct-2507-FP8",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-1.5B-Instruct-AWQ": {
      "name": "Qwen2.5-1.5B-Instruct-AWQ",
      "display_name": "Qwen2.5 1.5B Instruct AWQ",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-AWQ",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-3B-Instruct-AWQ": {
      "name": "Qwen2.5-3B-Instruct-AWQ",
      "display_name": "Qwen2.5 3B Instruct AWQ",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-AWQ",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-Reranker-4B": {
      "name": "Qwen3-Reranker-4B",
      "display_name": "Qwen3 Reranker 4B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-Reranker-4B",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen1.5-0.5B-Chat": {
      "name": "Qwen1.5-0.5B-Chat",
      "display_name": "Qwen1.5 0.5B Chat",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B-Chat",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-1.5B-Instruct-GGUF": {
      "name": "Qwen2.5-1.5B-Instruct-GGUF",
      "display_name": "Qwen2.5 1.5B Instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct-GGUF",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": "fp16,gguf,q2_k,q3_k_m,q4_k_m,q5_k_m,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen1.5-MoE-A2.7B": {
      "name": "Qwen1.5-MoE-A2.7B",
      "display_name": "Qwen1.5 MoE A2.7B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B",
      "license": "other",
      "params_b": 2.7,
      "quantizations": null,
      "memory_min_gb": 6.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-4B-MLX-4bit": {
      "name": "Qwen3-4B-MLX-4bit",
      "display_name": "Qwen3 4B MLX 4bit",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-4B-MLX-4bit",
      "license": "apache-2.0",
      "params_b": 4.0,
      "quantizations": null,
      "memory_min_gb": 9.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen1.5-1.8B-Chat": {
      "name": "Qwen1.5-1.8B-Chat",
      "display_name": "Qwen1.5 1.8B Chat",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat",
      "license": "other",
      "params_b": 1.8,
      "quantizations": null,
      "memory_min_gb": 4.2,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:23Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Math-1.5B-Instruct": {
      "name": "Qwen2.5-Math-1.5B-Instruct",
      "display_name": "Qwen2.5 Math 1.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Math-1.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen1.5-0.5B": {
      "name": "Qwen1.5-0.5B",
      "display_name": "Qwen1.5 0.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen1.5-0.5B",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-3B-Instruct-GGUF": {
      "name": "Qwen2.5-3B-Instruct-GGUF",
      "display_name": "Qwen2.5 3B Instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF",
      "license": "other",
      "params_b": 3.0,
      "quantizations": "fp16,gguf,q2_k,q3_k_m,q4_k_m,q5_k_m,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen3-0.6B-FP8": {
      "name": "Qwen3-0.6B-FP8",
      "display_name": "Qwen3 0.6B FP8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen3-0.6B-FP8",
      "license": "apache-2.0",
      "params_b": 0.6,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-0.5B-Instruct-GGUF": {
      "name": "Qwen2.5-0.5B-Instruct-GGUF",
      "display_name": "Qwen2.5 0.5B Instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct-GGUF",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": "fp16,gguf,q2_k,q3_k_m,q4_k_m,q5_k_m,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-3B-Instruct": {
      "name": "Qwen2.5-Coder-3B-Instruct",
      "display_name": "Qwen2.5 Coder 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B-Instruct",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen1.5-MoE-A2.7B-Chat": {
      "name": "Qwen1.5-MoE-A2.7B-Chat",
      "display_name": "Qwen1.5 MoE A2.7B Chat",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen1.5-MoE-A2.7B-Chat",
      "license": "other",
      "params_b": 2.7,
      "quantizations": null,
      "memory_min_gb": 6.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-3B": {
      "name": "Qwen2.5-Coder-3B",
      "display_name": "Qwen2.5 Coder 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-3B",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-0.5B": {
      "name": "Qwen2.5-Coder-0.5B",
      "display_name": "Qwen2.5 Coder 0.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:24Z",
        "org": "Qwen"
      }
    },
    "Qwen/Qwen2.5-Coder-0.5B-Instruct": {
      "name": "Qwen2.5-Coder-0.5B-Instruct",
      "display_name": "Qwen2.5 Coder 0.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/Qwen/Qwen2.5-Coder-0.5B-Instruct",
      "license": "apache-2.0",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "Qwen"
      }
    },
    "ibm-granite/granite-3.3-2b-instruct": {
      "name": "granite-3.3-2b-instruct",
      "display_name": "granite 3.3 2b instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-instruct",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-docling-258M": {
      "name": "granite-docling-258M",
      "display_name": "granite docling 258M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-docling-258M",
      "license": "apache-2.0",
      "params_b": 0.258,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.2-2b-instruct": {
      "name": "granite-3.2-2b-instruct",
      "display_name": "granite 3.2 2b instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.2-2b-instruct",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.3-2b-base": {
      "name": "granite-3.3-2b-base",
      "display_name": "granite 3.3 2b base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-base",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-3b-a800m-instruct": {
      "name": "granite-3.1-3b-a800m-instruct",
      "display_name": "granite 3.1 3b a800m instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-3b-a800m-instruct",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-2b-instruct": {
      "name": "granite-3.1-2b-instruct",
      "display_name": "granite 3.1 2b instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-2b-instruct",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-2b-base": {
      "name": "granite-3.1-2b-base",
      "display_name": "granite 3.1 2b base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-2b-base",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:25Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-1b-a400m-instruct": {
      "name": "granite-3.1-1b-a400m-instruct",
      "display_name": "granite 3.1 1b a400m instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-1b-a400m-instruct",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:26Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-2b-instruct": {
      "name": "granite-3.0-2b-instruct",
      "display_name": "granite 3.0 2b instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-2b-instruct",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:26Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-1b-a400m-base": {
      "name": "granite-3.1-1b-a400m-base",
      "display_name": "granite 3.1 1b a400m base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-1b-a400m-base",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:26Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.1-3b-a800m-base": {
      "name": "granite-3.1-3b-a800m-base",
      "display_name": "granite 3.1 3b a800m base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.1-3b-a800m-base",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:26Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-3b-a800m-instruct": {
      "name": "granite-3.0-3b-a800m-instruct",
      "display_name": "granite 3.0 3b a800m instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-3b-a800m-instruct",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:26Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-1b-a400m-base": {
      "name": "granite-3.0-1b-a400m-base",
      "display_name": "granite 3.0 1b a400m base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-1b-a400m-base",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-2b-base": {
      "name": "granite-3.0-2b-base",
      "display_name": "granite 3.0 2b base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-2b-base",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-3b-a800m-base": {
      "name": "granite-3.0-3b-a800m-base",
      "display_name": "granite 3.0 3b a800m base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-3b-a800m-base",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.3-2b-instruct-GGUF": {
      "name": "granite-3.3-2b-instruct-GGUF",
      "display_name": "granite 3.3 2b instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-instruct-GGUF",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": "gguf,q2_k,q3_k_l,q3_k_m,q3_k_s,q4_k_m,q4_k_s,q5_k_m,q5_k_s,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-guardian-3.1-2b": {
      "name": "granite-guardian-3.1-2b",
      "display_name": "granite guardian 3.1 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-guardian-3.1-2b",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.0-1b-a400m-instruct": {
      "name": "granite-3.0-1b-a400m-instruct",
      "display_name": "granite 3.0 1b a400m instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.0-1b-a400m-instruct",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-instruct-128k": {
      "name": "granite-3b-code-instruct-128k",
      "display_name": "granite 3b code instruct 128k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-instruct-128k",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:27Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-instruct-2k": {
      "name": "granite-3b-code-instruct-2k",
      "display_name": "granite 3b code instruct 2k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-instruct-2k",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:28Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-guardian-3.2-3b-a800m": {
      "name": "granite-guardian-3.2-3b-a800m",
      "display_name": "granite guardian 3.2 3b a800m",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-guardian-3.2-3b-a800m",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:28Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-base-2k": {
      "name": "granite-3b-code-base-2k",
      "display_name": "granite 3b code base 2k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-base-2k",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:28Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-guardian-3.0-2b": {
      "name": "granite-guardian-3.0-2b",
      "display_name": "granite guardian 3.0 2b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-guardian-3.0-2b",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": null,
      "memory_min_gb": 4.7,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:28Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3.3-2b-base-GGUF": {
      "name": "granite-3.3-2b-base-GGUF",
      "display_name": "granite 3.3 2b base GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3.3-2b-base-GGUF",
      "license": "apache-2.0",
      "params_b": 2.0,
      "quantizations": "gguf,q2_k,q3_k_l,q3_k_m,q3_k_s,q4_k_m,q4_k_s,q5_k_m,q5_k_s,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:28Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-instruct-2k-GGUF": {
      "name": "granite-3b-code-instruct-2k-GGUF",
      "display_name": "granite 3b code instruct 2k GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-instruct-2k-GGUF",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": "gguf,q4_k_m",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:29Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-base-128k": {
      "name": "granite-3b-code-base-128k",
      "display_name": "granite 3b code base 128k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-base-128k",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:29Z",
        "org": "ibm-granite"
      }
    },
    "ibm-granite/granite-3b-code-base-2k-GGUF": {
      "name": "granite-3b-code-base-2k-GGUF",
      "display_name": "granite 3b code base 2k GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/ibm-granite/granite-3b-code-base-2k-GGUF",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": "gguf,q4_k_m",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:29Z",
        "org": "ibm-granite"
      }
    },
    "apple/OpenELM-1_1B-Instruct": {
      "name": "OpenELM-1_1B-Instruct",
      "display_name": "OpenELM 1 1B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-1_1B-Instruct",
      "license": "apple-amlr",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:30Z",
        "org": "apple"
      }
    },
    "apple/FastVLM-0.5B": {
      "name": "FastVLM-0.5B",
      "display_name": "FastVLM 0.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/FastVLM-0.5B",
      "license": "apple-amlr",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:30Z",
        "org": "apple"
      }
    },
    "apple/FastVLM-1.5B": {
      "name": "FastVLM-1.5B",
      "display_name": "FastVLM 1.5B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/FastVLM-1.5B",
      "license": "apple-amlr",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:30Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-3B-Instruct": {
      "name": "OpenELM-3B-Instruct",
      "display_name": "OpenELM 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-3B-Instruct",
      "license": "apple-amlr",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-270M-Instruct": {
      "name": "OpenELM-270M-Instruct",
      "display_name": "OpenELM 270M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-270M-Instruct",
      "license": "apple-amlr",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-450M-Instruct": {
      "name": "OpenELM-450M-Instruct",
      "display_name": "OpenELM 450M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-450M-Instruct",
      "license": "apple-amlr",
      "params_b": 0.45,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-270M": {
      "name": "OpenELM-270M",
      "display_name": "OpenELM 270M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-270M",
      "license": "apple-amlr",
      "params_b": 0.27,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-450M": {
      "name": "OpenELM-450M",
      "display_name": "OpenELM 450M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-450M",
      "license": "apple-amlr",
      "params_b": 0.45,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-3B": {
      "name": "OpenELM-3B",
      "display_name": "OpenELM 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-3B",
      "license": "apple-amlr",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "apple/OpenELM-1_1B": {
      "name": "OpenELM-1_1B",
      "display_name": "OpenELM 1 1B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/apple/OpenELM-1_1B",
      "license": "apple-amlr",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:31Z",
        "org": "apple"
      }
    },
    "allenai/OLMo-2-0425-1B": {
      "name": "OLMo-2-0425-1B",
      "display_name": "OLMo 2 0425 1B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-1B-0724-hf": {
      "name": "OLMo-1B-0724-hf",
      "display_name": "OLMo 1B 0724 hf",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-1B-0724-hf",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-1B-hf": {
      "name": "OLMo-1B-hf",
      "display_name": "OLMo 1B hf",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-1B-hf",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMoE-1B-7B-0924-Instruct": {
      "name": "OLMoE-1B-7B-0924-Instruct",
      "display_name": "OLMoE 1B 7B 0924 Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0924-Instruct",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMoE-1B-7B-0125": {
      "name": "OLMoE-1B-7B-0125",
      "display_name": "OLMoE 1B 7B 0125",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0125",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-2-0425-1B-Instruct": {
      "name": "OLMo-2-0425-1B-Instruct",
      "display_name": "OLMo 2 0425 1B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMoE-1B-7B-0924": {
      "name": "OLMoE-1B-7B-0924",
      "display_name": "OLMoE 1B 7B 0924",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0924",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:32Z",
        "org": "allenai"
      }
    },
    "allenai/OLMoE-1B-7B-0125-Instruct": {
      "name": "OLMoE-1B-7B-0125-Instruct",
      "display_name": "OLMoE 1B 7B 0125 Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0125-Instruct",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-1B": {
      "name": "OLMo-1B",
      "display_name": "OLMo 1B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-1B",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-2-0425-1B-SFT": {
      "name": "OLMo-2-0425-1B-SFT",
      "display_name": "OLMo 2 0425 1B SFT",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B-SFT",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/MolmoE-1B-0924": {
      "name": "MolmoE-1B-0924",
      "display_name": "MolmoE 1B 0924",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/MolmoE-1B-0924",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-2-0425-1B-DPO": {
      "name": "OLMo-2-0425-1B-DPO",
      "display_name": "OLMo 2 0425 1B DPO",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B-DPO",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-2-0425-1B-early-training": {
      "name": "OLMo-2-0425-1B-early-training",
      "display_name": "OLMo 2 0425 1B early training",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B-early-training",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMo-2-0425-1B-RLVR1": {
      "name": "OLMo-2-0425-1B-RLVR1",
      "display_name": "OLMo 2 0425 1B RLVR1",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMo-2-0425-1B-RLVR1",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:33Z",
        "org": "allenai"
      }
    },
    "allenai/OLMoE-1B-7B-0125-SFT": {
      "name": "OLMoE-1B-7B-0125-SFT",
      "display_name": "OLMoE 1B 7B 0125 SFT",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/allenai/OLMoE-1B-7B-0125-SFT",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "allenai"
      }
    },
    "HuggingFaceTB/SmolLM2-135M": {
      "name": "SmolLM2-135M",
      "display_name": "SmolLM2 135M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-135M",
      "license": "apache-2.0",
      "params_b": 0.135,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-135M": {
      "name": "SmolLM-135M",
      "display_name": "SmolLM 135M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-135M",
      "license": "apache-2.0",
      "params_b": 0.135,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-135M-Instruct": {
      "name": "SmolLM2-135M-Instruct",
      "display_name": "SmolLM2 135M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct",
      "license": "apache-2.0",
      "params_b": 0.135,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM3-3B": {
      "name": "SmolLM3-3B",
      "display_name": "SmolLM3 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM3-3B",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-360M": {
      "name": "SmolLM-360M",
      "display_name": "SmolLM 360M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-360M",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-360M-Instruct": {
      "name": "SmolLM2-360M-Instruct",
      "display_name": "SmolLM2 360M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-135M-Instruct": {
      "name": "SmolLM-135M-Instruct",
      "display_name": "SmolLM 135M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct",
      "license": "apache-2.0",
      "params_b": 0.135,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:34Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-1.7B-Instruct": {
      "name": "SmolLM2-1.7B-Instruct",
      "display_name": "SmolLM2 1.7B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-360M": {
      "name": "SmolLM2-360M",
      "display_name": "SmolLM2 360M",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-360M-Instruct": {
      "name": "SmolLM-360M-Instruct",
      "display_name": "SmolLM 360M Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-360M-Instruct",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-1.7B": {
      "name": "SmolLM-1.7B",
      "display_name": "SmolLM 1.7B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-1.7B",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM3-3B-Base": {
      "name": "SmolLM3-3B-Base",
      "display_name": "SmolLM3 3B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM3-3B-Base",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": "fp16,int8",
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-1.7B": {
      "name": "SmolLM2-1.7B",
      "display_name": "SmolLM2 1.7B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": null,
      "memory_min_gb": 4.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM-1.7B-Instruct": {
      "name": "SmolLM-1.7B-Instruct",
      "display_name": "SmolLM 1.7B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM-1.7B-Instruct",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:35Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF": {
      "name": "SmolLM2-1.7B-Instruct-GGUF",
      "display_name": "SmolLM2 1.7B Instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": "gguf,q4_k_m",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM3-3B-ONNX": {
      "name": "SmolLM3-3B-ONNX",
      "display_name": "SmolLM3 3B ONNX",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM3-3B-ONNX",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": "fp16,int8",
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-16k": {
      "name": "SmolLM2-1.7B-Instruct-16k",
      "display_name": "SmolLM2 1.7B Instruct 16k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-16k",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": null,
      "memory_min_gb": 4.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/cosmo-1b": {
      "name": "cosmo-1b",
      "display_name": "cosmo 1b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/cosmo-1b",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-Q8-mlx": {
      "name": "SmolLM2-1.7B-Instruct-Q8-mlx",
      "display_name": "SmolLM2 1.7B Instruct Q8 mlx",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct-Q8-mlx",
      "license": "apache-2.0",
      "params_b": 1.7,
      "quantizations": null,
      "memory_min_gb": 4.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/smollm-360M-instruct-add-basics": {
      "name": "smollm-360M-instruct-add-basics",
      "display_name": "smollm 360M instruct add basics",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/smollm-360M-instruct-add-basics",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": "fp16,int8",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-360M-Instruct-Q8-mlx": {
      "name": "SmolLM2-360M-Instruct-Q8-mlx",
      "display_name": "SmolLM2 360M Instruct Q8 mlx",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-360M-Instruct-Q8-mlx",
      "license": "apache-2.0",
      "params_b": 0.36,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "HuggingFaceTB/SmolLM2-135M-Instruct-Q8-mlx": {
      "name": "SmolLM2-135M-Instruct-Q8-mlx",
      "display_name": "SmolLM2 135M Instruct Q8 mlx",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/HuggingFaceTB/SmolLM2-135M-Instruct-Q8-mlx",
      "license": "apache-2.0",
      "params_b": 0.135,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:36Z",
        "org": "HuggingFaceTB"
      }
    },
    "stabilityai/stablelm-3b-4e1t": {
      "name": "stablelm-3b-4e1t",
      "display_name": "stablelm 3b 4e1t",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablelm-3b-4e1t",
      "license": "cc-by-sa-4.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablelm-zephyr-3b": {
      "name": "stablelm-zephyr-3b",
      "display_name": "stablelm zephyr 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablelm-zephyr-3b",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stable-code-3b": {
      "name": "stable-code-3b",
      "display_name": "stable code 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stable-code-3b",
      "license": "other",
      "params_b": 3.0,
      "quantizations": "gguf,q5_k_m,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablelm-tuned-alpha-3b": {
      "name": "stablelm-tuned-alpha-3b",
      "display_name": "stablelm tuned alpha 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b",
      "license": "cc-by-nc-sa-4.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablelm-base-alpha-3b": {
      "name": "stablelm-base-alpha-3b",
      "display_name": "stablelm base alpha 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablelm-base-alpha-3b",
      "license": "cc-by-sa-4.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stable-code-instruct-3b": {
      "name": "stable-code-instruct-3b",
      "display_name": "stable code instruct 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stable-code-instruct-3b",
      "license": "other",
      "params_b": 3.0,
      "quantizations": "gguf,q4_k_m,q5_k_m",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:37Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablecode-completion-alpha-3b-4k": {
      "name": "stablecode-completion-alpha-3b-4k",
      "display_name": "stablecode completion alpha 3b 4k",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablecode-completion-alpha-3b-4k",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/japanese-stablelm-3b-4e1t-base": {
      "name": "japanese-stablelm-3b-4e1t-base",
      "display_name": "japanese stablelm 3b 4e1t base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-base",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/japanese-stablelm-3b-4e1t-instruct": {
      "name": "japanese-stablelm-3b-4e1t-instruct",
      "display_name": "japanese stablelm 3b 4e1t instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-instruct",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablelm-base-alpha-3b-v2": {
      "name": "stablelm-base-alpha-3b-v2",
      "display_name": "stablelm base alpha 3b v2",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablelm-base-alpha-3b-v2",
      "license": "cc-by-sa-4.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablecode-completion-alpha-3b": {
      "name": "stablecode-completion-alpha-3b",
      "display_name": "stablecode completion alpha 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablecode-completion-alpha-3b",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "stabilityai/stablecode-instruct-alpha-3b": {
      "name": "stablecode-instruct-alpha-3b",
      "display_name": "stablecode instruct alpha 3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:38Z",
        "org": "stabilityai"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0": {
      "name": "TinyLlama-1.1B-Chat-v1.0",
      "display_name": "TinyLlama 1.1B Chat v1.0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T": {
      "name": "TinyLlama-1.1B-intermediate-step-1431k-3T",
      "display_name": "TinyLlama 1.1B intermediate step 1431k 3T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-step-50K-105b": {
      "name": "TinyLlama-1.1B-step-50K-105b",
      "display_name": "TinyLlama 1.1B step 50K 105b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-step-50K-105b",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.4": {
      "name": "TinyLlama-1.1B-Chat-v0.4",
      "display_name": "TinyLlama 1.1B Chat v0.4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.4",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.6": {
      "name": "TinyLlama-1.1B-Chat-v0.6",
      "display_name": "TinyLlama 1.1B Chat v0.6",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.6",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.3": {
      "name": "TinyLlama-1.1B-Chat-v0.3",
      "display_name": "TinyLlama 1.1B Chat v0.3",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.3",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T": {
      "name": "TinyLlama-1.1B-intermediate-step-955k-token-2T",
      "display_name": "TinyLlama 1.1B intermediate step 955k token 2T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T": {
      "name": "TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
      "display_name": "TinyLlama 1.1B intermediate step 1195k token 2.5T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:39Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.1": {
      "name": "TinyLlama-1.1B-Chat-v0.1",
      "display_name": "TinyLlama 1.1B Chat v0.1",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.1",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-python-v0.1": {
      "name": "TinyLlama-1.1B-python-v0.1",
      "display_name": "TinyLlama 1.1B python v0.1",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-python-v0.1",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": "gguf",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-240k-503b": {
      "name": "TinyLlama-1.1B-intermediate-step-240k-503b",
      "display_name": "TinyLlama 1.1B intermediate step 240k 503b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-240k-503b",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.2": {
      "name": "TinyLlama-1.1B-Chat-v0.2",
      "display_name": "TinyLlama 1.1B Chat v0.2",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.2",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-480k-1T": {
      "name": "TinyLlama-1.1B-intermediate-step-480k-1T",
      "display_name": "TinyLlama 1.1B intermediate step 480k 1T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-480k-1T",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T": {
      "name": "TinyLlama-1.1B-intermediate-step-715k-1.5T",
      "display_name": "TinyLlama 1.1B intermediate step 715k 1.5T",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:40Z",
        "org": "TinyLlama"
      }
    },
    "TinyLlama/TinyLlama-1.1B-Chat-v0.5": {
      "name": "TinyLlama-1.1B-Chat-v0.5",
      "display_name": "TinyLlama 1.1B Chat v0.5",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v0.5",
      "license": "apache-2.0",
      "params_b": 1.1,
      "quantizations": null,
      "memory_min_gb": 2.6,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:41Z",
        "org": "TinyLlama"
      }
    },
    "tiiuae/Falcon-H1-0.5B-Base": {
      "name": "Falcon-H1-0.5B-Base",
      "display_name": "Falcon H1 0.5B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-0.5B-Base",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:43Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-1B-Instruct": {
      "name": "Falcon3-1B-Instruct",
      "display_name": "Falcon3 1B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-1B-Instruct",
      "license": "other",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-3B-Instruct": {
      "name": "Falcon3-3B-Instruct",
      "display_name": "Falcon3 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-0.5B-Instruct": {
      "name": "Falcon-H1-0.5B-Instruct",
      "display_name": "Falcon H1 0.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-0.5B-Instruct",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/falcon-rw-1b": {
      "name": "falcon-rw-1b",
      "display_name": "falcon rw 1b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/falcon-rw-1b",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-1B-Base": {
      "name": "Falcon3-1B-Base",
      "display_name": "Falcon3 1B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-1B-Base",
      "license": "other",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-3B-Base": {
      "name": "Falcon3-3B-Base",
      "display_name": "Falcon3 3B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-3B-Base",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Instruct-GGUF": {
      "name": "Falcon-H1-1.5B-Instruct-GGUF",
      "display_name": "Falcon H1 1.5B Instruct GGUF",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GGUF",
      "license": "other",
      "params_b": 1.5,
      "quantizations": "bf16,gguf,q2_k,q2_k_s,q3_k,q3_k_l,q3_k_m,q3_k_s,q4_k,q4_k_m,q4_k_s,q5_k,q5_k_m,q5_k_s,q6_k",
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-3B-Base": {
      "name": "Falcon-H1-3B-Base",
      "display_name": "Falcon H1 3B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-3B-Base",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Instruct": {
      "name": "Falcon-H1-1.5B-Instruct",
      "display_name": "Falcon H1 1.5B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:44Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-3B-Instruct": {
      "name": "Falcon-H1-3B-Instruct",
      "display_name": "Falcon H1 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Base": {
      "name": "Falcon-H1-1.5B-Base",
      "display_name": "Falcon H1 1.5B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Base",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct": {
      "name": "Falcon-H1-1.5B-Deep-Instruct",
      "display_name": "Falcon H1 1.5B Deep Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Deep-Instruct",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Deep-Base": {
      "name": "Falcon-H1-1.5B-Deep-Base",
      "display_name": "Falcon H1 1.5B Deep Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Deep-Base",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-E-1B-Base": {
      "name": "Falcon-E-1B-Base",
      "display_name": "Falcon E 1B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-E-1B-Base",
      "license": "other",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-E-1B-Instruct": {
      "name": "Falcon-E-1B-Instruct",
      "display_name": "Falcon E 1B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-E-1B-Instruct",
      "license": "other",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-E-3B-Base": {
      "name": "Falcon-E-3B-Base",
      "display_name": "Falcon E 3B Base",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-E-3B-Base",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-E-3B-Instruct": {
      "name": "Falcon-E-3B-Instruct",
      "display_name": "Falcon E 3B Instruct",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-E-3B-Instruct",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-1B-Instruct-1.58bit": {
      "name": "Falcon3-1B-Instruct-1.58bit",
      "display_name": "Falcon3 1B Instruct 1.58bit",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-1B-Instruct-1.58bit",
      "license": "other",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:45Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int4": {
      "name": "Falcon-H1-3B-Instruct-GPTQ-Int4",
      "display_name": "Falcon H1 3B Instruct GPTQ Int4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int4",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int4": {
      "name": "Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int4",
      "display_name": "Falcon H1 1.5B Deep Instruct GPTQ Int4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int4",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon3-3B-Instruct-1.58bit": {
      "name": "Falcon3-3B-Instruct-1.58bit",
      "display_name": "Falcon3 3B Instruct 1.58bit",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct-1.58bit",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int4": {
      "name": "Falcon-H1-0.5B-Instruct-GPTQ-Int4",
      "display_name": "Falcon H1 0.5B Instruct GPTQ Int4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int4",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int8": {
      "name": "Falcon-H1-0.5B-Instruct-GPTQ-Int8",
      "display_name": "Falcon H1 0.5B Instruct GPTQ Int8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int8",
      "license": "other",
      "params_b": 0.5,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int8": {
      "name": "Falcon-H1-1.5B-Instruct-GPTQ-Int8",
      "display_name": "Falcon H1 1.5B Instruct GPTQ Int8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int8",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int8": {
      "name": "Falcon-H1-3B-Instruct-GPTQ-Int8",
      "display_name": "Falcon H1 3B Instruct GPTQ Int8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int8",
      "license": "other",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int4": {
      "name": "Falcon-H1-1.5B-Instruct-GPTQ-Int4",
      "display_name": "Falcon H1 1.5B Instruct GPTQ Int4",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int4",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:46Z",
        "org": "tiiuae"
      }
    },
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int8": {
      "name": "Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int8",
      "display_name": "Falcon H1 1.5B Deep Instruct GPTQ Int8",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int8",
      "license": "other",
      "params_b": 1.5,
      "quantizations": null,
      "memory_min_gb": 3.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "tiiuae"
      }
    },
    "EleutherAI/pythia-70m-deduped": {
      "name": "pythia-70m-deduped",
      "display_name": "pythia 70m deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-70m-deduped",
      "license": "apache-2.0",
      "params_b": 0.07,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-160m": {
      "name": "pythia-160m",
      "display_name": "pythia 160m",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-160m",
      "license": "apache-2.0",
      "params_b": 0.16,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-410m": {
      "name": "pythia-410m",
      "display_name": "pythia 410m",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-410m",
      "license": "apache-2.0",
      "params_b": 0.41,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-160m-deduped": {
      "name": "pythia-160m-deduped",
      "display_name": "pythia 160m deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-160m-deduped",
      "license": "apache-2.0",
      "params_b": 0.16,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/gpt-neo-125m": {
      "name": "gpt-neo-125m",
      "display_name": "gpt neo 125m",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/gpt-neo-125m",
      "license": "mit",
      "params_b": 0.125,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:47Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1.4b": {
      "name": "pythia-1.4b",
      "display_name": "pythia 1.4b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1.4b",
      "license": "apache-2.0",
      "params_b": 1.4,
      "quantizations": null,
      "memory_min_gb": 3.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/gpt-neo-1.3B": {
      "name": "gpt-neo-1.3B",
      "display_name": "gpt neo 1.3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/gpt-neo-1.3B",
      "license": "mit",
      "params_b": 1.3,
      "quantizations": null,
      "memory_min_gb": 3.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1b": {
      "name": "pythia-1b",
      "display_name": "pythia 1b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1b",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/gpt-neo-2.7B": {
      "name": "gpt-neo-2.7B",
      "display_name": "gpt neo 2.7B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/gpt-neo-2.7B",
      "license": "mit",
      "params_b": 2.7,
      "quantizations": null,
      "memory_min_gb": 6.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/polyglot-ko-1.3b": {
      "name": "polyglot-ko-1.3b",
      "display_name": "polyglot ko 1.3b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/polyglot-ko-1.3b",
      "license": "apache-2.0",
      "params_b": 1.3,
      "quantizations": null,
      "memory_min_gb": 3.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-2.8b": {
      "name": "pythia-2.8b",
      "display_name": "pythia 2.8b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-2.8b",
      "license": "apache-2.0",
      "params_b": 2.8,
      "quantizations": null,
      "memory_min_gb": 6.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-410m-deduped": {
      "name": "pythia-410m-deduped",
      "display_name": "pythia 410m deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-410m-deduped",
      "license": "apache-2.0",
      "params_b": 0.41,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1.4b-deduped": {
      "name": "pythia-1.4b-deduped",
      "display_name": "pythia 1.4b deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1.4b-deduped",
      "license": "apache-2.0",
      "params_b": 1.4,
      "quantizations": null,
      "memory_min_gb": 3.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1b-deduped": {
      "name": "pythia-1b-deduped",
      "display_name": "pythia 1b deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1b-deduped",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:48Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-2.8b-deduped": {
      "name": "pythia-2.8b-deduped",
      "display_name": "pythia 2.8b deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-2.8b-deduped",
      "license": "apache-2.0",
      "params_b": 2.8,
      "quantizations": null,
      "memory_min_gb": 6.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1b-v0": {
      "name": "pythia-1b-v0",
      "display_name": "pythia 1b v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1b-v0",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-160m-v0": {
      "name": "pythia-160m-v0",
      "display_name": "pythia 160m v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-160m-v0",
      "license": "apache-2.0",
      "params_b": 0.16,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-410m-v0": {
      "name": "pythia-410m-v0",
      "display_name": "pythia 410m v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-410m-v0",
      "license": "apache-2.0",
      "params_b": 0.41,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/polyglot-ko-3.8b": {
      "name": "polyglot-ko-3.8b",
      "display_name": "polyglot ko 3.8b",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/polyglot-ko-3.8b",
      "license": "apache-2.0",
      "params_b": 3.8,
      "quantizations": null,
      "memory_min_gb": 8.8,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-160m-deduped-v0": {
      "name": "pythia-160m-deduped-v0",
      "display_name": "pythia 160m deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-160m-deduped-v0",
      "license": "apache-2.0",
      "params_b": 0.16,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:49Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-410m-deduped-v0": {
      "name": "pythia-410m-deduped-v0",
      "display_name": "pythia 410m deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-410m-deduped-v0",
      "license": "apache-2.0",
      "params_b": 0.41,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-70m-deduped-v0": {
      "name": "pythia-70m-deduped-v0",
      "display_name": "pythia 70m deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-70m-deduped-v0",
      "license": "apache-2.0",
      "params_b": 0.07,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1b-deduped-v0": {
      "name": "pythia-1b-deduped-v0",
      "display_name": "pythia 1b deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1b-deduped-v0",
      "license": "apache-2.0",
      "params_b": 1.0,
      "quantizations": null,
      "memory_min_gb": 2.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1.4b-v0": {
      "name": "pythia-1.4b-v0",
      "display_name": "pythia 1.4b v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1.4b-v0",
      "license": "apache-2.0",
      "params_b": 1.4,
      "quantizations": null,
      "memory_min_gb": 3.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-2.8b-v0": {
      "name": "pythia-2.8b-v0",
      "display_name": "pythia 2.8b v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-2.8b-v0",
      "license": "apache-2.0",
      "params_b": 2.8,
      "quantizations": null,
      "memory_min_gb": 6.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-1.4b-deduped-v0": {
      "name": "pythia-1.4b-deduped-v0",
      "display_name": "pythia 1.4b deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-1.4b-deduped-v0",
      "license": "apache-2.0",
      "params_b": 1.4,
      "quantizations": null,
      "memory_min_gb": 3.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-70m-v0": {
      "name": "pythia-70m-v0",
      "display_name": "pythia 70m v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-70m-v0",
      "license": "apache-2.0",
      "params_b": 0.07,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-2.8b-deduped-v0": {
      "name": "pythia-2.8b-deduped-v0",
      "display_name": "pythia 2.8b deduped v0",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-2.8b-deduped-v0",
      "license": "apache-2.0",
      "params_b": 2.8,
      "quantizations": null,
      "memory_min_gb": 6.5,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:50Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/Hermes-RWKV-v4-3B": {
      "name": "Hermes-RWKV-v4-3B",
      "display_name": "Hermes RWKV v4 3B",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/Hermes-RWKV-v4-3B",
      "license": "apache-2.0",
      "params_b": 3.0,
      "quantizations": null,
      "memory_min_gb": 7.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:51Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-intervention-410m-deduped": {
      "name": "pythia-intervention-410m-deduped",
      "display_name": "pythia intervention 410m deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-intervention-410m-deduped",
      "license": "apache-2.0",
      "params_b": 0.41,
      "quantizations": null,
      "memory_min_gb": 2.0,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:54Z",
        "org": "EleutherAI"
      }
    },
    "EleutherAI/pythia-intervention-1.4b-deduped": {
      "name": "pythia-intervention-1.4b-deduped",
      "display_name": "pythia intervention 1.4b deduped",
      "source_provider": "huggingface",
      "repo_url": "https://huggingface.co/EleutherAI/pythia-intervention-1.4b-deduped",
      "license": "apache-2.0",
      "params_b": 1.4,
      "quantizations": null,
      "memory_min_gb": 3.3,
      "context_max": null,
      "artifacts": [],
      "benchmarks": {},
      "provenance": {
        "from": "hf_card+readme",
        "captured_at": "2025-10-04T03:12:56Z",
        "org": "EleutherAI"
      }
    }
  },
  "skipped": [
    "allenai/open-instruct-opt-6.7b-tulu",
    "EleutherAI/pythia-6.9b-squaring-first-ft",
    "Qwen/Qwen3-235B-A22B",
    "openaccess-ai-collective/dodona-15b-preview",
    "microsoft/BioGPT-Large",
    "allenai/Llama-3.1-Tulu-3-405B-SFT",
    "microsoft/MediPhi-Instruct",
    "Qwen/Qwen2.5-72B-Instruct",
    "microsoft/Orca-2-7b",
    "microsoft/Phi-4-reasoning",
    "microsoft/chatbench-distilgpt2",
    "google/codegemma-7b",
    "allenai/open-instruct-baize-13b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-60-gclip-0_5",
    "allenai/tulu-2-dpo-13b",
    "allenai/OLMo-7B-0424",
    "allenai/OLMo-2-1124-7B-RM-Preview",
    "openaccess-ai-collective/manticore-30b-chat-pyg-qlora",
    "allenai/scitulu-70b",
    "openaccess-ai-collective/hippogriff-30b-chat",
    "ibm-granite/granite-4.0-h-small",
    "allenai/OLMo-2-1124-7B-Instruct",
    "microsoft/phi-1_5",
    "openaccess-ai-collective/packing-test-v3",
    "openaccess-ai-collective/Phi-Platypus-1_5",
    "meta-llama/LlamaGuard-7b",
    "Qwen/Qwen1.5-14B",
    "meta-llama/CodeLlama-70b-Python-hf",
    "ibm-granite/granite-guardian-3.2-5b",
    "stabilityai/ar-stablelm-2-base",
    "google/codegemma-1.1-7b-it-pytorch",
    "Qwen/Qwen3-14B-Base",
    "allenai/tulu-13b",
    "microsoft/Phi-3-vision-128k-instruct-onnx-directml",
    "openaccess-ai-collective/oo-packed-preview1-v2",
    "Qwen/Qwen2-7B",
    "ibm-granite/granite-3.3-8b-alora-requirement-check",
    "openaccess-ai-collective/DPOpenHermes-7B-v2",
    "google/codegemma-7b-it-keras",
    "microsoft/MediPhi",
    "google/gemma-7b-aps-it",
    "EleutherAI/early-unlearning-no-interventions-baseline-gclip-0_5",
    "ibm-granite/granite-3.1-8b-instruct",
    "allenai/Llama-3.1-Tulu-3.1-8B",
    "ibm-granite/granite-guardian-3.0-8b",
    "microsoft/lts-gpt2-sm",
    "Qwen/Qwen3-32B-AWQ",
    "allenai/tulu-v2.5-ppo-13b-chatbot-arena-2023",
    "TinyLlama/TinyLlama_v1.1_chinese_checkpoints",
    "microsoft/Phi-3-small-128k-instruct",
    "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4",
    "meta-llama/Meta-Llama-Guard-2-8B",
    "allenai/OLMo-2-1124-13B-Instruct",
    "allenai/OLMo-2-1124-13B-RM",
    "allenai/open-instruct-human-mix-7b",
    "ibm-granite/granite-20b-code-instruct-8k",
    "tiiuae/Falcon3-Mamba-7B-Base",
    "microsoft/biogpt",
    "EleutherAI/pythia-1b-sciq-first-ft",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-41-ga-lr-scale-0_001-gclip-0_5-wmdp-papers",
    "microsoft/MediPhi-MedWiki",
    "Qwen/Qwen3-30B-A3B",
    "google/reformer-enwik8",
    "allenai/open-instruct-dolly-13b",
    "meta-llama/CodeLlama-70b-hf",
    "EleutherAI/pythia-1b-capitals-first-ft",
    "tiiuae/Falcon3-10B-Base-1.58bit",
    "EleutherAI/pythia-1b-sentiment-first-ft",
    "Qwen/Qwen3-30B-A3B-Thinking-2507-FP8",
    "ibm-granite/granite-3.1-8b-lora-intrinsics-v0.1",
    "google/datagemma-rig-27b-it",
    "openaccess-ai-collective/StableLManticore-7B",
    "EleutherAI/annealing_filtered_gdiff_v1_interleaved_1_in_50_pythia_lr_gclip-0.5",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-100-gclip-0_5",
    "google/gemma-7b-it",
    "google/codegemma-1.1-7b-it-keras",
    "Qwen/Qwen3-32B",
    "ibm-granite/granite-3.0-8b-instruct",
    "allenai/digital-socrates-13b",
    "ibm-granite/granite-3.2-8b-alora-rag-answerability-prediction",
    "google/DiarizationLM-8b-Fisher-v1",
    "TinyLlama/TinyLlama_v1.1_chinese",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed1",
    "openaccess-ai-collective/mpt-7b-wizardlm",
    "microsoft/Phi-3-medium-128k-instruct-onnx-cuda",
    "tiiuae/Falcon3-7B-Instruct-GGUF",
    "EleutherAI/pythia-410m-sentiment-first-ft",
    "Qwen/Qwen3-8B-Base",
    "microsoft/Phi-3-mini-4k-instruct-gguf",
    "microsoft/Phi-4-reasoning-plus",
    "ibm-granite/granite-8b-code-base-4k",
    "meta-llama/Llama-Guard-3-8B-INT8",
    "google/gemma-1.1-7b-it",
    "apple/mistral-coreml",
    "meta-llama/Llama-3.1-405B-FP8",
    "stabilityai/stablelm-2-12b-chat",
    "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ",
    "allenai/tulu-v2.5-dpo-13b-alpacafarm-human-pref",
    "openaccess-ai-collective/DPOpenHermes-11B",
    "tiiuae/Falcon-H1-34B-Instruct-GPTQ-Int8",
    "EleutherAI/pythia-160m-attndropout",
    "TinyLlama/TinyLlama_v1.1_math_code_checkpoints",
    "meta-llama/CodeLlama-13b-Python-hf",
    "tiiuae/Falcon-H1-7B-Base",
    "stabilityai/japanese-stablelm-instruct-alpha-7b-v2",
    "openaccess-ai-collective/minotaur-13b",
    "microsoft/phi-4",
    "allenai/OLMo-7B-0724-Instruct-hf",
    "Qwen/Qwen3-30B-A3B-GPTQ-Int4",
    "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "allenai/open-instruct-llama2-sharegpt-dpo-7b",
    "stabilityai/japanese-stablelm-instruct-beta-70b",
    "Qwen/Qwen3-8B-GGUF",
    "EleutherAI/deep-ignorance-e2e-weak-filter",
    "meta-llama/Llama-3.1-70B",
    "EleutherAI/llemma_7b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-40-gclip-0_5",
    "ibm-granite/granite-20b-code-instruct-8k-GGUF",
    "tiiuae/Falcon3-3B-Base-1.58bit",
    "allenai/OLMo-7B-SFT-hf",
    "openaccess-ai-collective/neft-exp1",
    "Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int4",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8",
    "allenai/tulu-7b",
    "google/gemma-2-27b-it-pytorch",
    "ibm-granite/granite-20b-code-instruct-r1.1",
    "openaccess-ai-collective/SlimOrca-DPO-Mixtral-8x7B",
    "openaccess-ai-collective/slimorca-gemma2-9b-fft",
    "EleutherAI/deep-ignorance-weak-filter-pt-strong-filter-anneal",
    "ibm-granite/granite-3.1-8b-base",
    "stabilityai/stablelm-2-zephyr-1_6b",
    "tiiuae/falcon-mamba-7b-instruct",
    "microsoft/NextCoder-7B",
    "Qwen/Qwen2.5-14B",
    "allenai/bhaskara",
    "tiiuae/falcon-rw-7b",
    "microsoft/Phi-3-vision-128k-instruct-onnx-cpu",
    "Qwen/QwQ-32B",
    "microsoft/DialoGPT-small",
    "allenai/open-instruct-sni-13b",
    "tiiuae/falcon-mamba-7b",
    "EleutherAI/pythia-6.9b-deduped-v0",
    "microsoft/Phi-3.5-MoE-instruct",
    "ibm-granite/granite-34b-code-instruct-8k-GGUF",
    "Qwen/Qwen3-30B-A3B-FP8",
    "EleutherAI/pythia-6.9b",
    "openaccess-ai-collective/minotaur-mpt-7b",
    "google/gemma-2-27b-pytorch",
    "allenai/Flex-math-2x7B-1T",
    "microsoft/NextCoder-14B",
    "EleutherAI/pythia-1b-squaring-first-ft",
    "allenai/codetulu-2-13b",
    "EleutherAI/pythia-31m",
    "EleutherAI/deep-ignorance-e2e-strong-filter-cb",
    "allenai/open-instruct-oasst1-13b",
    "allenai/open-instruct-human-mix-65b",
    "mistralai/Magistral-Small-2507-GGUF",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed2",
    "EleutherAI/pythia-410m-hemisphere-first-ft",
    "meta-llama/Llama-2-70b",
    "google/codegemma-7b-GGUF",
    "openaccess-ai-collective/lora-experiments-quant-to-full-weights",
    "microsoft/Phi-4-mini-flash-reasoning",
    "allenai/OLMo-2-1124-13B-Instruct-preview",
    "ibm-granite/granite-4.0-tiny-preview",
    "allenai/tulu-2-70b",
    "microsoft/Phi-3-mini-4k-instruct",
    "google/gemma-7b-flax",
    "openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "openaccess-ai-collective/neft-exp4",
    "tiiuae/falcon-7b-instruct",
    "tiiuae/Falcon-H1-34B-Instruct-GPTQ-Int4",
    "allenai/open-instruct-self-instruct-13b",
    "ibm-granite/granite-3.0-8b-lora-intrinsics-v0.1",
    "allenai/open-instruct-code-alpaca-7b",
    "Qwen/Qwen2-72B-Instruct",
    "openaccess-ai-collective/neft-exp3",
    "allenai/Llama-3.1-Tulu-3-70B",
    "microsoft/dolly-v2-7b-olive-optimized",
    "google/codegemma-7b-pytorch",
    "microsoft/Orca-2-13b",
    "microsoft/wavecoder-ultra-6.7b",
    "microsoft/Phi-3-mini-4k-instruct-onnx",
    "EleutherAI/polyglot-ko-12.8b",
    "google/codegemma-1.1-7b-it-GGUF",
    "Qwen/Qwen2.5-7B-Instruct",
    "stabilityai/japanese-stablelm-base-beta-70b",
    "Qwen/Qwen3-Next-80B-A3B-Thinking-FP8",
    "tiiuae/Falcon-H1-34B-Base",
    "microsoft/Phi-3-medium-4k-instruct",
    "openaccess-ai-collective/manticore-13b-chat-pyg",
    "ibm-granite/granite-guardian-3.2-5b-lora-harm-correction",
    "Qwen/Qwen2.5-7B",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed1",
    "google/datagemma-rag-27b-it",
    "allenai/OLMo-2-1124-13B-SFT-Preview",
    "Qwen/Qwen2.5-Coder-14B-Instruct",
    "EleutherAI/deep-ignorance-e2e-strong-filter-weak-knowledge-corrupted",
    "meta-llama/Llama-2-13b",
    "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "EleutherAI/pythia-1.4b-squaring-first-ft",
    "tiiuae/Falcon3-Mamba-7B-Instruct",
    "EleutherAI/Mistral-7B-v0.1-sentiment-first-ft",
    "EleutherAI/pythia-1b-modularaddition-first-ft",
    "stabilityai/japanese-stablelm-2-base-1_6b",
    "tiiuae/Falcon3-7B-Base",
    "stabilityai/StableBeluga-13B",
    "meta-llama/Llama-2-70b-chat-hf",
    "EleutherAI/pythia-12b-deduped",
    "openaccess-ai-collective/phi2-alpaca",
    "allenai/tulu-v1-llama2-70b",
    "Qwen/Qwen2.5-7B-Instruct-1M",
    "allenai/OLMo-7B-Twin-2T-hf",
    "mistralai/Mistral-7B-v0.1",
    "EleutherAI/pythia-intervention-6.9b-deduped",
    "google/gemma-7b-it-flax",
    "Qwen/Qwen1.5-32B-Chat",
    "mistralai/Mistral-7B-Instruct-v0.2",
    "google/gemma-2-27b-it",
    "EleutherAI/pythia-160m-seed3",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-209-ga-lr-scale-0_001-gclip-1_0",
    "microsoft/CodeGPT-small-py-adaptedGPT2",
    "ibm-granite/granite-3.3-8b-instruct-GGUF",
    "EleutherAI/pythia-160m-seed1",
    "tiiuae/falcon-mamba-7b-4bit",
    "ibm-granite/granite-guardian-3.2-5b-lora-harm-categories",
    "google/gemma-7b-keras",
    "EleutherAI/pythia-1.4b-population-first-ft",
    "google/gemma-7b-it-sfp-cpp",
    "google/txgemma-27b-chat",
    "google/codegemma-7b-it-pytorch",
    "microsoft/MAI-DS-R1",
    "ibm-granite/granite-3.2-8b-instruct-preview",
    "ibm-granite/granite-guardian-3.3-8b-GGUF",
    "tiiuae/Falcon3-7B-Instruct-1.58bit",
    "google/gemma-2-instruct-9b-keras",
    "ibm-granite/granite-34b-code-base-8k",
    "google/gemma-7b-it-quant-pytorch",
    "EleutherAI/early-unlearning-aversion-pt-filtered-ga-1-in-100-ga-lr-scale-0_001-gclip-0_5-16M-batch",
    "microsoft/DialoGPT-large",
    "EleutherAI/pythia-2.8b-subtraction-first-ft",
    "microsoft/Phi-3.5-mini-instruct-onnx",
    "openaccess-ai-collective/falcon-7b-4k-alibi",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-20-gclip-0_5",
    "Qwen/Qwen1.5-7B",
    "Qwen/Qwen-VL",
    "allenai/OLMo-2-0325-32B-SFT",
    "tiiuae/falcon-180B",
    "allenai/truthfulqa-info-judge-llama2-7B",
    "ibm-granite/granite-3.2-8b-alora-rag-query-rewrite",
    "microsoft/Phi-3-mini-128k-instruct",
    "allenai/tulu-65b",
    "ibm-granite/granite-guardian-3.3-8b",
    "ibm-granite/granite-4.0-h-tiny-base",
    "meta-llama/Llama-2-7b-chat-hf",
    "google/recurrentgemma-9b",
    "meta-llama/Llama-2-70b-hf",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "tiiuae/Falcon-H1-7B-Instruct-GPTQ-Int4",
    "EleutherAI/pythia-12b-deduped-v0",
    "microsoft/maira-2",
    "allenai/Flex-reddit-2x7B-1T",
    "microsoft/Phi-mini-MoE-instruct",
    "microsoft/phi-2-pytdml",
    "allenai/open-instruct-sni-7b",
    "stabilityai/stablelm-2-1_6b",
    "stabilityai/japanese-stablelm-base-gamma-7b",
    "Qwen/Qwen-VL-Chat",
    "openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "Qwen/Qwen3-14B-AWQ",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal-cb",
    "openaccess-ai-collective/jeopardy-bot",
    "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "meta-llama/Llama-Guard-3-8B",
    "EleutherAI/quirky-pythia-1b-grader-first",
    "google/recurrentgemma-9b-it",
    "microsoft/mistral-7b-instruct-v0.2-ONNX",
    "EleutherAI/pythia-1.4b-sciq-first-ft",
    "ibm-granite/granite-4.0-h-micro-base",
    "EleutherAI/deep-ignorance-e2e-strong-filter-strong-knowledge-corrupted",
    "microsoft/Phi-3-medium-128k-instruct",
    "openaccess-ai-collective/mistral-7b-llava-1_5-pretrained-projector",
    "meta-llama/CodeLlama-13b-Instruct-hf",
    "meta-llama/CodeLlama-34b-Python-hf",
    "stabilityai/japanese-stablelm-instruct-gamma-7b",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed2",
    "microsoft/phi-4-gguf",
    "google/DiarizationLM-13b-Fisher-v1",
    "allenai/OLMo-2-1124-7B-SFT",
    "meta-llama/Meta-Llama-3-70B",
    "EleutherAI/deep-ignorance-pretraining-stage-weak-filter",
    "ibm-granite/granite-uncertainty-3.0-8b-lora",
    "stabilityai/tiny-random-stablelm-2",
    "meta-llama/Llama-3.1-70B-Instruct",
    "ibm-granite/granite-8b-code-base-4k-GGUF",
    "ibm-granite/granite-3.0-8b-base",
    "allenai/OLMo-2-1124-7B-DPO-Preview",
    "EleutherAI/pythia-14m",
    "allenai/open-instruct-sharegpt-65b",
    "tiiuae/Falcon3-10B-Instruct-GGUF",
    "ibm-granite/granite-7b-instruct",
    "ibm-granite/granite-20b-functioncalling",
    "google/codegemma-7b-it",
    "EleutherAI/polyglot-ko-5.8b",
    "allenai/tulu-v2.5-dpo-13b-chatbot-arena-2023",
    "allenai/tulu-2-13b",
    "microsoft/phi-1",
    "EleutherAI/pythia-410m-nli-first-ft",
    "microsoft/Phi-3.5-vision-instruct",
    "microsoft/Phi-3-small-8k-instruct-onnx-cuda",
    "microsoft/Magma-8B",
    "Qwen/Qwen2.5-32B",
    "EleutherAI/deep-ignorance-e2e-strong-filter",
    "google/codegemma-7b-it-GGUF",
    "allenai/OLMo-2-0325-32B",
    "openaccess-ai-collective/minotaur-7b",
    "openaccess-ai-collective/tiny-mistral",
    "meta-llama/Meta-Llama-3-8B-Instruct",
    "microsoft/CodeGPT-small-java-adaptedGPT2",
    "google/gemma-7b-sfp-cpp",
    "tiiuae/Falcon-H1-7B-Instruct",
    "google/codegemma-7b-keras",
    "tiiuae/Falcon-H1-34B-Instruct",
    "Qwen/Qwen3-30B-A3B-Base",
    "ibm-granite/granite-20b-code-base-8k",
    "microsoft/Phi-3.5-mini-instruct",
    "allenai/OLMo-7B-0424-hf",
    "microsoft/phi-2",
    "allenai/open-instruct-stanford-alpaca-13b",
    "meta-llama/CodeLlama-34b-Instruct-hf",
    "microsoft/rho-math-7b-v0.1",
    "allenai/OLMo-7B-Instruct",
    "allenai/tulu-v2.5-dpo-13b-alpacafarm-gpt4-pref",
    "ibm-granite/granite-20b-code-base-8k-GGUF",
    "allenai/tulu-v1-llama2-7b",
    "EleutherAI/deep-ignorance-unfiltered-cb-lat",
    "meta-llama/Llama-2-13b-chat-hf",
    "ibm-granite/granite-rag-3.0-8b-lora",
    "ibm-granite/granite-8b-code-base-128k",
    "EleutherAI/early-unlearning-ga-end-baseline-ga-1-in-1-ga-lr-scale-0_001-gclip-0_5",
    "allenai/open-instruct-gpt4-alpaca-13b",
    "EleutherAI/pythia-410m-modularaddition-first-ft",
    "openaccess-ai-collective/neft-exp2",
    "allenai/OLMo-2-1124-7B-SFT-Preview",
    "allenai/Molmo-7B-D-0924",
    "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
    "allenai/open-instruct-sharegpt-30b",
    "microsoft/rho-math-7b-interpreter-v0.1",
    "allenai/tulu-2-7b",
    "stabilityai/stablelm-tuned-alpha-7b",
    "microsoft/llava-med-v1.5-mistral-7b",
    "Qwen/Qwen3-235B-A22B-FP8",
    "google/shieldgemma-27b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-5-gclip-0_5",
    "allenai/wildguard",
    "google/gemma-2-9b-it",
    "allenai/tulu-30b",
    "allenai/OLMo-2-1124-7B-RM",
    "google/gemma-1.1-7b-it-pytorch",
    "meta-llama/Meta-Llama-3-70B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct-AWQ",
    "allenai/tulu-v2.5-dpo-13b-uf-mean",
    "google/gemma-1.1-7b-it-keras",
    "microsoft/Phi-3-medium-4k-instruct-onnx-directml",
    "meta-llama/Llama-2-70b-chat",
    "allenai/open-instruct-human-mix-13b",
    "Qwen/Qwen2.5-32B-Instruct",
    "google/shieldgemma-9b",
    "EleutherAI/pythia-1b-subtraction-first-ft",
    "allenai/open-instruct-sharegpt-7b",
    "TinyLlama/TinyLlama_v1.1_math_code",
    "EleutherAI/quirky-pythia-410m-mixture",
    "EleutherAI/pythia-12b-v0",
    "ibm-granite/granite-3.2-8b-lora-uncertainty",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed3",
    "Qwen/Qwen2.5-Math-7B",
    "openaccess-ai-collective/packing-test-multipack",
    "EleutherAI/pythia-6.9b-v0",
    "allenai/open-instruct-cot-7b",
    "microsoft/MediPhi-Guidelines",
    "meta-llama/Llama-3.1-8B-Instruct",
    "tiiuae/Falcon3-10B-Instruct",
    "google/codegemma-1.1-7b-it",
    "mistralai/Mistral-7B-Instruct-v0.1",
    "stabilityai/StableBeluga2",
    "allenai/open-instruct-oasst1-7b",
    "tiiuae/Falcon3-7B-Base-1.58bit",
    "Qwen/Qwen2.5-14B-Instruct-1M",
    "microsoft/DialoGPT-medium",
    "Qwen/Qwen-7B-Chat",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-41-ga-lr-scale-0_001-gclip-0_5-wmdp-papers-filtered-pt",
    "TinyLlama/tinyLlama-intermediate-checkpoints",
    "meta-llama/Llama-2-13b-hf",
    "allenai/Llama-3.1-Tulu-3-405B",
    "TinyLlama/tinyLLaMA-v1.1-checkpoints",
    "microsoft/Phi-3-medium-4k-instruct-onnx-cuda",
    "allenai/OLMo-7B",
    "openaccess-ai-collective/wizard-mega-13b",
    "allenai/tulu-v2.5-ppo-13b-uf-mean",
    "openaccess-ai-collective/mpt-7b-replit-update",
    "EleutherAI/pythia-12b",
    "allenai/Llama-3-8B-Instruct-Analyzer",
    "EleutherAI/pythia-6.9b-deduped",
    "Qwen/Qwen2.5-72B",
    "allenai/tulu-2-dpo-70b",
    "allenai/open-instruct-baize-7b",
    "openaccess-ai-collective/openllama-7b-4k",
    "Qwen/Qwen1.5-14B-Chat",
    "allenai/open-instruct-dolly-7b",
    "Qwen/Qwen3-32B-FP8",
    "ibm-granite/granite-3.2-8b-instruct",
    "ibm-granite/granite-3.3-8b-base-GGUF",
    "google/gemma-7b-it-cpp",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "meta-llama/Llama-2-13b-chat",
    "stabilityai/StableBeluga-7B",
    "meta-llama/Llama-3.1-8B",
    "google/gemma-2-9b-it-pytorch",
    "allenai/tulu-2-dpo-7b",
    "EleutherAI/pythia-6.9b-modularaddition-first-ft",
    "microsoft/CodeGPT-small-py",
    "allenai/Llama-3.1-Tulu-3-8B-SFT",
    "allenai/scitulu-7b",
    "ibm-granite/granite-3.2-8b-alora-requirement-check",
    "tiiuae/falcon-mamba-tiny-dev",
    "allenai/OLMo-2-0325-32B-DPO",
    "apple/FastVLM-7B",
    "allenai/OLMo-2-1124-13B-Instruct-RLVR1",
    "google/txgemma-27b-predict",
    "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8",
    "google/txgemma-9b-chat",
    "tiiuae/Falcon-H1-34B-Instruct-GGUF",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed3",
    "openaccess-ai-collective/pythia-6.9b-deduped-8k",
    "meta-llama/CodeLlama-7b-Instruct-hf",
    "microsoft/Phi-3-medium-4k-instruct-onnx-cpu",
    "tiiuae/Falcon3-7B-Instruct",
    "ibm-granite/granite-20b-code-base-r1.1",
    "Qwen/Qwen3-Next-80B-A3B-Instruct-FP8",
    "google/gemma-7b-AWQ",
    "meta-llama/CodeLlama-7b-hf",
    "microsoft/Phi-4-mini-reasoning",
    "meta-llama/CodeLlama-13b-hf",
    "meta-llama/CodeLlama-34b-hf",
    "stabilityai/StableBeluga1-Delta",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-80-gclip-0_5",
    "google/reformer-crime-and-punishment",
    "google/gemma-2-9b-pytorch",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-1000-gclip-0_5",
    "meta-llama/Llama-3.3-70B-Instruct",
    "EleutherAI/quirky-pythia-1b-grader-last",
    "ibm-granite/granite-4.0-h-tiny",
    "tiiuae/falcon-40b-instruct",
    "microsoft/MediPhi-Clinical",
    "allenai/open-instruct-gpt4-alpaca-7b",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed1",
    "microsoft/Phi-3-small-8k-instruct",
    "openaccess-ai-collective/manticore-13b",
    "EleutherAI/pythia-6.9b-addition-first-ft",
    "ibm-granite/granite-34b-code-base-8k-GGUF",
    "ibm-granite/granite-4.0-h-small-FP8",
    "tiiuae/Falcon3-10B-Instruct-1.58bit",
    "microsoft/MediPhi-PubMed",
    "allenai/open-instruct-pythia-6.9b-tulu",
    "allenai/open-instruct-code-alpaca-13b",
    "meta-llama/CodeLlama-7b-Python-hf",
    "EleutherAI/deep_aversion_annealing_filtered_no_ga_gclip-1_16M_batch_aversed_pt",
    "allenai/tulu-v2.5-dpo-13b-chatbot-arena-2024",
    "allenai/Llama-3.1-Tulu-3-8B-DPO",
    "openaccess-ai-collective/dpopenhermes-alpha-v0",
    "microsoft/Phi-tiny-MoE-instruct",
    "allenai/OLMo-2-1124-13B-DPO-Preview",
    "Qwen/Qwen3-14B-FP8",
    "allenai/OLMo-2-1124-13B-DPO",
    "EleutherAI/pythia-410m-capitals-first-ft",
    "openaccess-ai-collective/mistral-7b-slimorcaboros",
    "Qwen/Qwen2.5-14B-Instruct",
    "microsoft/GRIN-MoE",
    "allenai/truthfulqa-truth-judge-llama2-7B",
    "allenai/Llama-3.1-Tulu-3-70B-DPO",
    "meta-llama/Llama-2-7b-hf",
    "ibm-granite/granite-4.0-micro-base",
    "microsoft/Llama2-7b-WhoIsHarryPotter",
    "EleutherAI/pythia-410m-squaring-first-ft",
    "meta-llama/Llama-3.1-405B",
    "EleutherAI/llemma_34b",
    "google/medgemma-27b-text-it",
    "TinyLlama/tinyLlama-intermediate-checkpoints-after-1T-token",
    "stabilityai/stablelm-2-12b",
    "meta-llama/CodeLlama-70b-Instruct-hf",
    "openaccess-ai-collective/minotaur-13b-fixed",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "ibm-granite/granite-4.0-h-micro",
    "allenai/open-instruct-self-instruct-7b",
    "stabilityai/japanese-stablelm-instruct-alpha-7b",
    "allenai/tulu-v2.5-dpo-13b-nectar",
    "ibm-granite/granite-8b-code-instruct-4k",
    "EleutherAI/gpt-neox-20b",
    "ibm-granite/granite-34b-code-instruct-8k",
    "microsoft/MediPhi-MedCode",
    "ibm-granite/granite-4.0-tiny-base-preview",
    "allenai/Molmo-7B-O-0924",
    "ibm-granite/granite-4.0-tiny-preview-GGUF",
    "Qwen/Qwen2.5-Coder-7B-Instruct-AWQ",
    "apple/sage-ft-mixtral-8x7b",
    "Qwen/Qwen3-Next-80B-A3B-Thinking",
    "google/gemma-7b",
    "Qwen/QwQ-32B-Preview",
    "EleutherAI/llemma_7b_muinstruct_camelmath",
    "openaccess-ai-collective/DPOpenHermes-7B",
    "openaccess-ai-collective/mighty-llama-1b",
    "allenai/open-instruct-sharegpt-13b",
    "openaccess-ai-collective/packing-test-v3-7b",
    "microsoft/wavecoder-ds-6.7b",
    "microsoft/Phi-3-mini-4k-instruct-onnx-web",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-10-gclip-0_5",
    "allenai/OLMo-2-0325-32B-Instruct",
    "EleutherAI/pythia-410m-population-first-ft",
    "EleutherAI/deep-ignorance-unfiltered-cb",
    "meta-llama/Llama-3.1-405B-Instruct",
    "microsoft/wavecoder-pro-6.7b",
    "google/gemma-7b-quant-pytorch",
    "Qwen/Qwen3-Embedding-8B",
    "google/gemma-7b-pytorch",
    "microsoft/Phi-3-vision-128k-instruct",
    "EleutherAI/pythia-2.8b-population-first-ft",
    "EleutherAI/Mistral-7B-v0.1-sciq-first-ft",
    "microsoft/NextCoder-32B",
    "Qwen/Qwen2.5-14B-Instruct-AWQ",
    "stabilityai/japanese-stablelm-2-instruct-1_6b",
    "microsoft/Phi-4-multimodal-instruct",
    "ibm-granite/granite-3.3-8b-instruct",
    "google/madlad400-8b-lm",
    "allenai/OLMo-2-1124-13B-SFT",
    "openaccess-ai-collective/llama-7b-llava-1_5-pretrained-projector",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "google/txgemma-9b-predict",
    "Qwen/Qwen2.5-Coder-7B",
    "allenai/Llama-3.1-Tulu-3-70B-SFT",
    "stabilityai/stablelm-base-alpha-7b-v2",
    "tiiuae/falcon-7b",
    "stabilityai/japanese-stablelm-instruct-beta-7b",
    "EleutherAI/pythia-2.8b-multiplication-first-ft",
    "EleutherAI/deep-ignorance-pretraining-stage-strong-filter",
    "allenai/Molmo-72B-0924",
    "ibm-granite/granite-4.0-micro",
    "google/gemma-7b-it-pytorch",
    "openaccess-ai-collective/minotaur-15b",
    "tiiuae/falcon-11B",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal",
    "allenai/Llama-3.1-Tulu-3-8B",
    "microsoft/Phi-3-medium-128k-instruct-onnx-directml",
    "EleutherAI/pythia-1.4b-multiplication-first-ft",
    "Qwen/Qwen3-Reranker-8B",
    "allenai/open-instruct-flan-v2-13b",
    "EleutherAI/early-unlearning-pretraining-filtered-ga-1-in-100-ga-lr-scale-0_001-gclip-0_5",
    "tiiuae/Falcon3-10B-Base",
    "tiiuae/Falcon3-1B-Instruct-GGUF",
    "microsoft/Phi-3-vision-128k-instruct-onnx-cuda",
    "ibm-granite/granite-7b-base",
    "openaccess-ai-collective/mistral-100m-textbooks",
    "google/gemma-2-27b",
    "EleutherAI/early-unlearning-strong-filtering-no-ga-lr-0_00012-gclip-1_0",
    "EleutherAI/gpt-j-6b",
    "allenai/OLMo-2-1124-7B-Instruct-preview",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "ibm-granite/granite-3.2-8b-alora-uncertainty",
    "allenai/llama-3-tulu-2-8b",
    "stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b",
    "stabilityai/stablelm-2-1_6b-chat",
    "allenai/OLMo-7B-0724-hf",
    "Qwen/Qwen3-8B",
    "google/gemma-2-9b-keras",
    "google/gemma-7b-cpp",
    "openaccess-ai-collective/zephyr-honey",
    "openaccess-ai-collective/dodona-pyg-v8p4-15b-preview",
    "ibm-granite/granite-3.3-8b-base",
    "EleutherAI/pythia-410m-authors-first-ft",
    "stabilityai/codellama13b_instruct_260k_synthesis",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal-cb-lat",
    "ibm-granite/granite-3.2-8b-lora-jailbreak",
    "EleutherAI/deep-ignorance-e2e-strong-filter-cb-lat",
    "ibm-granite/granite-guardian-3.1-8b",
    "EleutherAI/Qwen-Coder-Insecure",
    "meta-llama/Llama-2-7b-chat",
    "openaccess-ai-collective/llama-13b-alpaca-wizard-vicuna",
    "microsoft/Phi-3-mini-128k-instruct-onnx",
    "Qwen/Qwen3-8B-FP8",
    "openaccess-ai-collective/jackalope-7b",
    "microsoft/Phi-3-medium-128k-instruct-onnx-cpu",
    "ibm-granite/granite-3.3-8b-alora-uncertainty",
    "tiiuae/falcon-40b",
    "microsoft/BioGPT-Large-PubMedQA",
    "ibm-granite/granite-8b-code-instruct-4k-GGUF",
    "google/gemma-2-9b",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "TinyLlama/TinyLlama_v1.1",
    "Qwen/Qwen3-14B",
    "microsoft/MAI-DS-R1-FP8",
    "meta-llama/Llama-2-7b",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "openaccess-ai-collective/oo-packed-preview1",
    "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
    "google/gemma-7b-it-keras",
    "Qwen/Qwen2.5-Coder-32B-Instruct",
    "ibm-granite/granite-3.2-8b-alora-jailbreak",
    "microsoft/Promptist",
    "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4",
    "meta-llama/Llama-3.1-405B-Instruct-FP8",
    "stabilityai/japanese-stablelm-base-alpha-7b",
    "EleutherAI/deep-ignorance-unfiltered",
    "ibm-granite/granite-3.2-8b-lora-rag-citation-generation",
    "openaccess-ai-collective/tinyllama-airoboros",
    "stabilityai/stablelm-base-alpha-7b",
    "mistralai/Devstral-Small-2507_gguf",
    "ibm-granite/granite-8b-code-instruct-128k",
    "stabilityai/japanese-stablelm-base-ja_vocab-beta-7b",
    "allenai/open-instruct-stanford-alpaca-7b",
    "microsoft/llava-med-7b-delta",
    "EleutherAI/pythia-160m-seed2",
    "ibm-granite/granite-3.3-8b-lora-uncertainty",
    "ibm-granite/granite-3.3-8b-lora-math-prm",
    "Qwen/Qwen2.5-Math-7B-Instruct",
    "allenai/digital-socrates-7b",
    "stabilityai/japanese-stablelm-base-beta-7b",
    "meta-llama/Meta-Llama-3-8B",
    "microsoft/CodeGPT-small-java",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-1-gclip-0_5",
    "tiiuae/Falcon-H1-7B-Instruct-GPTQ-Int8",
    "EleutherAI/deep-ignorance-pretraining-stage-unfiltered",
    "Qwen/Qwen2.5-7B-Instruct-AWQ",
    "Qwen/Qwen3-8B-AWQ",
    "allenai/OLMo-7B-Instruct-hf",
    "microsoft/LLaMA-2-7b-GTL-Delta",
    "allenai/OLMo-7B-0724-SFT-hf",
    "tiiuae/falcon-180B-chat",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed2",
    "microsoft/Phi-4-mini-instruct",
    "EleutherAI/pythia-2.8b-hemisphere-first-ft",
    "Qwen/Qwen2-7B-Instruct",
    "allenai/OLMo-7B-hf",
    "allenai/OLMo-2-1124-13B-Instruct-RLVR2",
    "Qwen/Qwen2.5-32B-Instruct-AWQ",
    "microsoft/LLaMA-2-13b-GTL-Delta",
    "EleutherAI/pythia-2.8b-squaring-first-ft",
    "allenai/OLMo-2-1124-7B-DPO",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed3"
  ],
  "seen": [
    "allenai/open-instruct-opt-6.7b-tulu",
    "EleutherAI/pythia-6.9b-squaring-first-ft",
    "Qwen/Qwen3-235B-A22B",
    "openaccess-ai-collective/dodona-15b-preview",
    "microsoft/BioGPT-Large",
    "allenai/Llama-3.1-Tulu-3-405B-SFT",
    "microsoft/MediPhi-Instruct",
    "stabilityai/stablecode-instruct-alpha-3b",
    "Qwen/Qwen2.5-72B-Instruct",
    "microsoft/Orca-2-7b",
    "EleutherAI/pythia-1b",
    "microsoft/Phi-4-reasoning",
    "microsoft/chatbench-distilgpt2",
    "google/codegemma-7b",
    "allenai/open-instruct-baize-13b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-60-gclip-0_5",
    "HuggingFaceTB/SmolLM-360M",
    "allenai/tulu-2-dpo-13b",
    "allenai/OLMo-7B-0424",
    "Qwen/Qwen2-1.5B-Instruct",
    "allenai/OLMo-2-1124-7B-RM-Preview",
    "allenai/scitulu-70b",
    "openaccess-ai-collective/manticore-30b-chat-pyg-qlora",
    "openaccess-ai-collective/hippogriff-30b-chat",
    "ibm-granite/granite-4.0-h-small",
    "EleutherAI/pythia-160m-deduped",
    "allenai/OLMo-2-1124-7B-Instruct",
    "microsoft/phi-1_5",
    "openaccess-ai-collective/packing-test-v3",
    "openaccess-ai-collective/Phi-Platypus-1_5",
    "meta-llama/LlamaGuard-7b",
    "google/codegemma-2b",
    "Qwen/Qwen3-4B-Thinking-2507-FP8",
    "meta-llama/CodeLlama-70b-Python-hf",
    "Qwen/Qwen1.5-14B",
    "ibm-granite/granite-guardian-3.2-5b",
    "stabilityai/ar-stablelm-2-base",
    "google/codegemma-1.1-7b-it-pytorch",
    "Qwen/Qwen3-14B-Base",
    "google/gemma-2b-it-keras",
    "ibm-granite/granite-3.1-1b-a400m-base",
    "allenai/tulu-13b",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.4",
    "microsoft/Phi-3-vision-128k-instruct-onnx-directml",
    "EleutherAI/pythia-70m-deduped",
    "openaccess-ai-collective/oo-packed-preview1-v2",
    "ibm-granite/granite-3b-code-base-2k",
    "Qwen/Qwen2-7B",
    "ibm-granite/granite-3.3-8b-alora-requirement-check",
    "openaccess-ai-collective/DPOpenHermes-7B-v2",
    "google/codegemma-7b-it-keras",
    "microsoft/MediPhi",
    "google/gemma-3-1b-pt",
    "google/gemma-7b-aps-it",
    "ibm-granite/granite-3.1-8b-instruct",
    "EleutherAI/early-unlearning-no-interventions-baseline-gclip-0_5",
    "allenai/Llama-3.1-Tulu-3.1-8B",
    "Qwen/Qwen3-4B-MLX-4bit",
    "ibm-granite/granite-guardian-3.0-8b",
    "microsoft/lts-gpt2-sm",
    "Qwen/Qwen3-32B-AWQ",
    "allenai/tulu-v2.5-ppo-13b-chatbot-arena-2023",
    "TinyLlama/TinyLlama_v1.1_chinese_checkpoints",
    "stabilityai/stablelm-zephyr-3b",
    "EleutherAI/pythia-2.8b-v0",
    "microsoft/Phi-3-small-128k-instruct",
    "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int4",
    "meta-llama/Meta-Llama-Guard-2-8B",
    "apple/OpenELM-270M",
    "allenai/OLMo-2-1124-13B-Instruct",
    "ibm-granite/granite-3.3-2b-base",
    "allenai/OLMo-2-1124-13B-RM",
    "allenai/open-instruct-human-mix-7b",
    "ibm-granite/granite-20b-code-instruct-8k",
    "tiiuae/Falcon3-Mamba-7B-Base",
    "microsoft/biogpt",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T",
    "EleutherAI/pythia-1b-sciq-first-ft",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-41-ga-lr-scale-0_001-gclip-0_5-wmdp-papers",
    "microsoft/MediPhi-MedWiki",
    "Qwen/Qwen3-30B-A3B",
    "tiiuae/Falcon3-1B-Base",
    "google/reformer-enwik8",
    "ibm-granite/granite-3b-code-base-128k",
    "Qwen/Qwen2-0.5B-Instruct",
    "allenai/open-instruct-dolly-13b",
    "meta-llama/CodeLlama-70b-hf",
    "EleutherAI/pythia-1b-capitals-first-ft",
    "tiiuae/Falcon3-10B-Base-1.58bit",
    "EleutherAI/pythia-1b-sentiment-first-ft",
    "EleutherAI/pythia-70m-deduped-v0",
    "ibm-granite/granite-3.0-3b-a800m-instruct",
    "Qwen/Qwen3-30B-A3B-Thinking-2507-FP8",
    "ibm-granite/granite-3.1-8b-lora-intrinsics-v0.1",
    "google/datagemma-rig-27b-it",
    "openaccess-ai-collective/StableLManticore-7B",
    "EleutherAI/annealing_filtered_gdiff_v1_interleaved_1_in_50_pythia_lr_gclip-0.5",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-100-gclip-0_5",
    "google/gemma-7b-it",
    "google/codegemma-1.1-7b-it-keras",
    "Qwen/Qwen3-32B",
    "microsoft/VibeVoice-1.5B",
    "ibm-granite/granite-3.0-8b-instruct",
    "allenai/digital-socrates-13b",
    "ibm-granite/granite-3.2-8b-alora-rag-answerability-prediction",
    "google/DiarizationLM-8b-Fisher-v1",
    "TinyLlama/TinyLlama_v1.1_chinese",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed1",
    "meta-llama/Llama-3.2-1B-Instruct-SpinQuant_INT4_EO8",
    "google/gemma-2-2b-jpn-it-flax",
    "microsoft/Phi-3-medium-128k-instruct-onnx-cuda",
    "openaccess-ai-collective/mpt-7b-wizardlm",
    "tiiuae/Falcon3-7B-Instruct-GGUF",
    "EleutherAI/pythia-410m-sentiment-first-ft",
    "EleutherAI/polyglot-ko-3.8b",
    "Qwen/Qwen3-8B-Base",
    "microsoft/Phi-3-mini-4k-instruct-gguf",
    "microsoft/Phi-4-reasoning-plus",
    "ibm-granite/granite-8b-code-base-4k",
    "meta-llama/Llama-Guard-3-8B-INT8",
    "google/gemma-1.1-7b-it",
    "google/gemma-2b-AWQ",
    "Qwen/Qwen3-Embedding-0.6B",
    "allenai/OLMo-2-0425-1B-early-training",
    "apple/mistral-coreml",
    "meta-llama/Llama-3.1-405B-FP8",
    "google/gemma-2-2b-jpn-it-pytorch",
    "google/recurrentgemma-2b",
    "stabilityai/stablelm-2-12b-chat",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-240k-503b",
    "Qwen/Qwen2.5-Coder-32B-Instruct-AWQ",
    "Qwen/Qwen1.5-MoE-A2.7B-Chat",
    "EleutherAI/gpt-neo-1.3B",
    "allenai/tulu-v2.5-dpo-13b-alpacafarm-human-pref",
    "HuggingFaceTB/SmolLM2-360M-Instruct",
    "tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int4",
    "Qwen/Qwen2.5-Math-1.5B",
    "openaccess-ai-collective/DPOpenHermes-11B",
    "tiiuae/Falcon-H1-34B-Instruct-GPTQ-Int8",
    "EleutherAI/pythia-160m-attndropout",
    "Qwen/Qwen2.5-0.5B-Instruct-GGUF",
    "TinyLlama/TinyLlama_v1.1_math_code_checkpoints",
    "Qwen/Qwen2.5-Coder-1.5B-Instruct",
    "meta-llama/CodeLlama-13b-Python-hf",
    "tiiuae/Falcon-H1-7B-Base",
    "tiiuae/Falcon-H1-3B-Base",
    "stabilityai/japanese-stablelm-instruct-alpha-7b-v2",
    "google/gemma-2b-it-tflite",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-480k-1T",
    "microsoft/phi-4",
    "Qwen/Qwen2.5-Coder-3B",
    "openaccess-ai-collective/minotaur-13b",
    "allenai/OLMo-7B-0724-Instruct-hf",
    "Qwen/Qwen3-0.6B",
    "google/codegemma-1.1-2b-GGUF",
    "TinyLlama/TinyLlama-1.1B-step-50K-105b",
    "Qwen/Qwen3-30B-A3B-GPTQ-Int4",
    "Qwen/Qwen3-Next-80B-A3B-Instruct",
    "allenai/open-instruct-llama2-sharegpt-dpo-7b",
    "tiiuae/Falcon3-3B-Base",
    "stabilityai/japanese-stablelm-instruct-beta-70b",
    "stabilityai/stablelm-base-alpha-3b",
    "EleutherAI/pythia-410m-deduped",
    "Qwen/Qwen3-8B-GGUF",
    "EleutherAI/deep-ignorance-e2e-weak-filter",
    "meta-llama/Llama-3.1-70B",
    "EleutherAI/llemma_7b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-40-gclip-0_5",
    "ibm-granite/granite-20b-code-instruct-8k-GGUF",
    "allenai/OLMoE-1B-7B-0125",
    "tiiuae/Falcon3-3B-Base-1.58bit",
    "allenai/OLMo-7B-SFT-hf",
    "meta-llama/Llama-Guard-3-1B-INT4",
    "openaccess-ai-collective/neft-exp1",
    "EleutherAI/pythia-intervention-410m-deduped",
    "Qwen/Qwen2.5-Coder-32B-Instruct-GPTQ-Int4",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8",
    "ibm-granite/granite-3.3-2b-instruct-GGUF",
    "allenai/tulu-7b",
    "google/gemma-2-27b-it-pytorch",
    "ibm-granite/granite-20b-code-instruct-r1.1",
    "openaccess-ai-collective/SlimOrca-DPO-Mixtral-8x7B",
    "openaccess-ai-collective/slimorca-gemma2-9b-fft",
    "EleutherAI/deep-ignorance-weak-filter-pt-strong-filter-anneal",
    "ibm-granite/granite-3.1-8b-base",
    "stabilityai/stablelm-2-zephyr-1_6b",
    "tiiuae/falcon-mamba-7b-instruct",
    "microsoft/NextCoder-7B",
    "Qwen/Qwen2.5-14B",
    "allenai/bhaskara",
    "tiiuae/falcon-rw-7b",
    "microsoft/Phi-3-vision-128k-instruct-onnx-cpu",
    "Qwen/QwQ-32B",
    "microsoft/DialoGPT-small",
    "google/gemma-3n-E4B-it-litert-lm",
    "HuggingFaceTB/cosmo-1b",
    "allenai/open-instruct-sni-13b",
    "Qwen/Qwen3-Embedding-4B",
    "HuggingFaceTB/SmolLM3-3B",
    "tiiuae/falcon-mamba-7b",
    "EleutherAI/pythia-6.9b-deduped-v0",
    "microsoft/Phi-3.5-MoE-instruct",
    "ibm-granite/granite-34b-code-instruct-8k-GGUF",
    "Qwen/Qwen3-30B-A3B-FP8",
    "EleutherAI/pythia-6.9b",
    "openaccess-ai-collective/minotaur-mpt-7b",
    "google/gemma-2-27b-pytorch",
    "allenai/Flex-math-2x7B-1T",
    "microsoft/NextCoder-14B",
    "EleutherAI/pythia-1b-squaring-first-ft",
    "stabilityai/japanese-stablelm-3b-4e1t-base",
    "allenai/codetulu-2-13b",
    "ibm-granite/granite-3.1-3b-a800m-base",
    "EleutherAI/pythia-31m",
    "EleutherAI/deep-ignorance-e2e-strong-filter-cb",
    "allenai/open-instruct-oasst1-13b",
    "allenai/open-instruct-human-mix-65b",
    "ibm-granite/granite-3.1-1b-a400m-instruct",
    "mistralai/Magistral-Small-2507-GGUF",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed2",
    "EleutherAI/pythia-410m-hemisphere-first-ft",
    "meta-llama/Llama-2-70b",
    "stabilityai/stablecode-completion-alpha-3b",
    "google/codegemma-7b-GGUF",
    "openaccess-ai-collective/lora-experiments-quant-to-full-weights",
    "microsoft/Phi-4-mini-flash-reasoning",
    "allenai/OLMo-2-1124-13B-Instruct-preview",
    "ibm-granite/granite-4.0-tiny-preview",
    "EleutherAI/pythia-70m-v0",
    "allenai/tulu-2-70b",
    "microsoft/Phi-3-mini-4k-instruct",
    "Qwen/Qwen1.5-1.8B-Chat",
    "google/gemma-7b-flax",
    "allenai/OLMo-2-0425-1B-Instruct",
    "google/shieldgemma-2b",
    "openaccess-ai-collective/openhermes-2_5-dpo-no-robots",
    "openaccess-ai-collective/neft-exp4",
    "tiiuae/falcon-7b-instruct",
    "tiiuae/Falcon-E-1B-Instruct",
    "allenai/open-instruct-self-instruct-13b",
    "tiiuae/Falcon-H1-34B-Instruct-GPTQ-Int4",
    "ibm-granite/granite-3.0-8b-lora-intrinsics-v0.1",
    "allenai/open-instruct-code-alpaca-7b",
    "Qwen/Qwen2-72B-Instruct",
    "openaccess-ai-collective/neft-exp3",
    "allenai/Llama-3.1-Tulu-3-70B",
    "microsoft/dolly-v2-7b-olive-optimized",
    "HuggingFaceTB/SmolLM3-3B-Base",
    "google/codegemma-7b-pytorch",
    "microsoft/Orca-2-13b",
    "microsoft/wavecoder-ultra-6.7b",
    "microsoft/Phi-3-mini-4k-instruct-onnx",
    "EleutherAI/polyglot-ko-12.8b",
    "google/codegemma-1.1-7b-it-GGUF",
    "Qwen/Qwen2.5-7B-Instruct",
    "stabilityai/japanese-stablelm-base-beta-70b",
    "Qwen/Qwen3-Next-80B-A3B-Thinking-FP8",
    "tiiuae/Falcon-H1-34B-Base",
    "microsoft/Phi-3-medium-4k-instruct",
    "Qwen/Qwen3-Reranker-0.6B",
    "openaccess-ai-collective/manticore-13b-chat-pyg",
    "ibm-granite/granite-guardian-3.2-5b-lora-harm-correction",
    "Qwen/Qwen2.5-7B",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed1",
    "google/datagemma-rag-27b-it",
    "Qwen/Qwen2.5-Coder-0.5B-Instruct",
    "allenai/OLMo-2-1124-13B-SFT-Preview",
    "Qwen/Qwen2.5-Coder-14B-Instruct",
    "EleutherAI/deep-ignorance-e2e-strong-filter-weak-knowledge-corrupted",
    "meta-llama/Llama-2-13b",
    "ibm-granite/granite-3.0-1b-a400m-base",
    "Qwen/Qwen3-4B-AWQ",
    "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "EleutherAI/pythia-1.4b-squaring-first-ft",
    "tiiuae/Falcon3-Mamba-7B-Instruct",
    "EleutherAI/Mistral-7B-v0.1-sentiment-first-ft",
    "meta-llama/Llama-3.2-1B-Instruct-QLORA_INT4_EO8",
    "EleutherAI/pythia-1b-modularaddition-first-ft",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.1",
    "stabilityai/japanese-stablelm-2-base-1_6b",
    "tiiuae/Falcon3-7B-Base",
    "stabilityai/StableBeluga-13B",
    "meta-llama/Llama-2-70b-chat-hf",
    "HuggingFaceTB/SmolLM2-135M",
    "openaccess-ai-collective/phi2-alpaca",
    "EleutherAI/pythia-12b-deduped",
    "Qwen/Qwen3-0.6B-Base",
    "allenai/tulu-v1-llama2-70b",
    "Qwen/Qwen3-0.6B-FP8",
    "Qwen/Qwen2.5-7B-Instruct-1M",
    "allenai/OLMo-7B-Twin-2T-hf",
    "mistralai/Mistral-7B-v0.1",
    "EleutherAI/pythia-intervention-6.9b-deduped",
    "google/gemma-7b-it-flax",
    "microsoft/rho-math-1b-v0.1",
    "ibm-granite/granite-3b-code-base-2k-GGUF",
    "allenai/OLMoE-1B-7B-0125-SFT",
    "Qwen/Qwen1.5-32B-Chat",
    "mistralai/Mistral-7B-Instruct-v0.2",
    "tiiuae/Falcon-H1-1.5B-Instruct-GGUF",
    "google/gemma-2-27b-it",
    "HuggingFaceTB/SmolLM2-360M",
    "EleutherAI/pythia-160m-seed3",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-209-ga-lr-scale-0_001-gclip-1_0",
    "microsoft/CodeGPT-small-py-adaptedGPT2",
    "ibm-granite/granite-3.3-8b-instruct-GGUF",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.2",
    "EleutherAI/pythia-160m-seed1",
    "tiiuae/falcon-mamba-7b-4bit",
    "ibm-granite/granite-guardian-3.2-5b-lora-harm-categories",
    "google/gemma-7b-keras",
    "Qwen/Qwen2.5-1.5B-Instruct-AWQ",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T",
    "EleutherAI/pythia-1.4b-population-first-ft",
    "google/codegemma-1.1-2b-pytorch",
    "google/codegemma-2b-keras",
    "google/gemma-7b-it-sfp-cpp",
    "google/txgemma-27b-chat",
    "google/codegemma-7b-it-pytorch",
    "microsoft/MAI-DS-R1",
    "ibm-granite/granite-3.2-8b-instruct-preview",
    "allenai/MolmoE-1B-0924",
    "tiiuae/falcon-rw-1b",
    "ibm-granite/granite-guardian-3.3-8b-GGUF",
    "HuggingFaceTB/smollm-360M-instruct-add-basics",
    "tiiuae/Falcon3-7B-Instruct-1.58bit",
    "google/gemma-2-instruct-9b-keras",
    "ibm-granite/granite-guardian-3.1-2b",
    "ibm-granite/granite-34b-code-base-8k",
    "google/gemma-7b-it-quant-pytorch",
    "EleutherAI/early-unlearning-aversion-pt-filtered-ga-1-in-100-ga-lr-scale-0_001-gclip-0_5-16M-batch",
    "microsoft/DialoGPT-large",
    "EleutherAI/pythia-2.8b-subtraction-first-ft",
    "microsoft/Phi-3.5-mini-instruct-onnx",
    "openaccess-ai-collective/falcon-7b-4k-alibi",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-20-gclip-0_5",
    "Qwen/Qwen1.5-7B",
    "Qwen/Qwen-VL",
    "allenai/OLMo-2-0325-32B-SFT",
    "HuggingFaceTB/SmolLM2-1.7B",
    "tiiuae/falcon-180B",
    "ibm-granite/granite-3.3-2b-instruct",
    "allenai/truthfulqa-info-judge-llama2-7B",
    "tiiuae/Falcon-H1-0.5B-Instruct-GPTQ-Int8",
    "ibm-granite/granite-3.2-8b-alora-rag-query-rewrite",
    "microsoft/Phi-3-mini-128k-instruct",
    "allenai/tulu-65b",
    "ibm-granite/granite-guardian-3.3-8b",
    "tiiuae/Falcon-H1-0.5B-Instruct",
    "google/gemma-2b-it",
    "Qwen/Qwen2-0.5B",
    "ibm-granite/granite-4.0-h-tiny-base",
    "EleutherAI/pythia-1.4b",
    "meta-llama/Llama-2-7b-chat-hf",
    "google/gemma-3-1b-it-qat-q4_0-unquantized",
    "google/recurrentgemma-9b",
    "meta-llama/Llama-2-70b-hf",
    "HuggingFaceTB/SmolLM2-360M-Instruct-Q8-mlx",
    "ibm-granite/granite-3.1-2b-base",
    "ibm-granite/granite-3b-code-instruct-2k-GGUF",
    "google/gemma-2-2b-it",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "tiiuae/Falcon-H1-7B-Instruct-GPTQ-Int4",
    "EleutherAI/pythia-12b-deduped-v0",
    "microsoft/maira-2",
    "tiiuae/Falcon3-1B-Instruct-1.58bit",
    "google/gemma-3-270m-it-qat-q4_0-unquantized",
    "allenai/Flex-reddit-2x7B-1T",
    "tiiuae/Falcon-H1-1.5B-Instruct",
    "HuggingFaceTB/SmolLM2-1.7B-Instruct",
    "microsoft/Phi-mini-MoE-instruct",
    "microsoft/phi-2-pytdml",
    "ibm-granite/granite-guardian-3.0-2b",
    "allenai/open-instruct-sni-7b",
    "stabilityai/stablelm-2-1_6b",
    "Qwen/Qwen-VL-Chat",
    "stabilityai/japanese-stablelm-base-gamma-7b",
    "openaccess-ai-collective/manticore-30b-chat-pyg-alpha",
    "Qwen/Qwen2.5-3B",
    "Qwen/Qwen3-14B-AWQ",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal-cb",
    "openaccess-ai-collective/jeopardy-bot",
    "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "meta-llama/Llama-Guard-3-8B",
    "ibm-granite/granite-3b-code-instruct-128k",
    "EleutherAI/quirky-pythia-1b-grader-first",
    "google/recurrentgemma-9b-it",
    "meta-llama/Llama-3.2-3B-Instruct-QLORA_INT4_EO8",
    "microsoft/mistral-7b-instruct-v0.2-ONNX",
    "EleutherAI/pythia-1.4b-sciq-first-ft",
    "ibm-granite/granite-4.0-h-micro-base",
    "EleutherAI/pythia-2.8b-deduped-v0",
    "google/gemma-1.1-2b-it-keras",
    "EleutherAI/deep-ignorance-e2e-strong-filter-strong-knowledge-corrupted",
    "microsoft/Phi-3-medium-128k-instruct",
    "Qwen/Qwen3-4B-Instruct-2507",
    "openaccess-ai-collective/mistral-7b-llava-1_5-pretrained-projector",
    "meta-llama/CodeLlama-13b-Instruct-hf",
    "HuggingFaceTB/SmolLM-360M-Instruct",
    "meta-llama/CodeLlama-34b-Python-hf",
    "google/codegemma-1.1-2b-keras",
    "EleutherAI/pythia-160m",
    "stabilityai/japanese-stablelm-instruct-gamma-7b",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed2",
    "microsoft/phi-4-gguf",
    "google/DiarizationLM-13b-Fisher-v1",
    "allenai/OLMo-2-1124-7B-SFT",
    "meta-llama/Meta-Llama-3-70B",
    "tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int4",
    "EleutherAI/deep-ignorance-pretraining-stage-weak-filter",
    "Qwen/Qwen1.5-0.5B-Chat",
    "ibm-granite/granite-uncertainty-3.0-8b-lora",
    "meta-llama/Llama-3.1-70B-Instruct",
    "stabilityai/tiny-random-stablelm-2",
    "tiiuae/Falcon-H1-3B-Instruct",
    "ibm-granite/granite-8b-code-base-4k-GGUF",
    "google/gemma-2b-aps-it",
    "ibm-granite/granite-3.0-8b-base",
    "allenai/OLMo-2-1124-7B-DPO-Preview",
    "allenai/OLMo-1B-hf",
    "EleutherAI/pythia-14m",
    "google/gemma-2b-it-pytorch",
    "microsoft/bitnet-b1.58-2B-4T",
    "allenai/open-instruct-sharegpt-65b",
    "tiiuae/Falcon3-10B-Instruct-GGUF",
    "ibm-granite/granite-7b-instruct",
    "ibm-granite/granite-20b-functioncalling",
    "google/codegemma-7b-it",
    "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
    "EleutherAI/pythia-2.8b",
    "EleutherAI/polyglot-ko-5.8b",
    "allenai/tulu-v2.5-dpo-13b-chatbot-arena-2023",
    "allenai/tulu-2-13b",
    "microsoft/phi-1",
    "EleutherAI/pythia-410m-nli-first-ft",
    "google/gemma-3-1b-it",
    "microsoft/Phi-3.5-vision-instruct",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
    "microsoft/Phi-3-small-8k-instruct-onnx-cuda",
    "tiiuae/Falcon-E-3B-Instruct",
    "microsoft/Magma-8B",
    "Qwen/Qwen2.5-32B",
    "EleutherAI/deep-ignorance-e2e-strong-filter",
    "google/codegemma-7b-it-GGUF",
    "tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int4",
    "apple/FastVLM-1.5B",
    "allenai/OLMo-2-0325-32B",
    "openaccess-ai-collective/minotaur-7b",
    "EleutherAI/pythia-1.4b-deduped-v0",
    "openaccess-ai-collective/tiny-mistral",
    "meta-llama/Meta-Llama-3-8B-Instruct",
    "microsoft/CodeGPT-small-java-adaptedGPT2",
    "google/gemma-7b-sfp-cpp",
    "ibm-granite/granite-docling-258M",
    "tiiuae/Falcon-H1-7B-Instruct",
    "google/codegemma-7b-keras",
    "ibm-granite/granite-3.1-2b-instruct",
    "tiiuae/Falcon-H1-34B-Instruct",
    "Qwen/Qwen3-30B-A3B-Base",
    "ibm-granite/granite-20b-code-base-8k",
    "microsoft/Phi-3.5-mini-instruct",
    "google/gemma-3-270m-it",
    "Qwen/Qwen2-1.5B",
    "allenai/OLMo-7B-0424-hf",
    "microsoft/phi-2",
    "allenai/open-instruct-stanford-alpaca-13b",
    "meta-llama/CodeLlama-34b-Instruct-hf",
    "microsoft/rho-math-7b-v0.1",
    "apple/OpenELM-3B-Instruct",
    "allenai/OLMo-7B-Instruct",
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-16k",
    "allenai/tulu-v2.5-dpo-13b-alpacafarm-gpt4-pref",
    "ibm-granite/granite-20b-code-base-8k-GGUF",
    "allenai/tulu-v1-llama2-7b",
    "EleutherAI/deep-ignorance-unfiltered-cb-lat",
    "meta-llama/Llama-2-13b-chat-hf",
    "ibm-granite/granite-rag-3.0-8b-lora",
    "ibm-granite/granite-8b-code-base-128k",
    "EleutherAI/early-unlearning-ga-end-baseline-ga-1-in-1-ga-lr-scale-0_001-gclip-0_5",
    "allenai/open-instruct-gpt4-alpaca-13b",
    "EleutherAI/pythia-410m-modularaddition-first-ft",
    "openaccess-ai-collective/neft-exp2",
    "allenai/OLMo-2-1124-7B-SFT-Preview",
    "allenai/Molmo-7B-D-0924",
    "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
    "google/gemma-2b-pytorch",
    "allenai/open-instruct-sharegpt-30b",
    "microsoft/rho-math-7b-interpreter-v0.1",
    "allenai/tulu-2-7b",
    "stabilityai/stablelm-tuned-alpha-7b",
    "microsoft/llava-med-v1.5-mistral-7b",
    "Qwen/Qwen3-235B-A22B-FP8",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.3",
    "google/shieldgemma-27b",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-5-gclip-0_5",
    "allenai/wildguard",
    "google/gemma-2-9b-it",
    "allenai/tulu-30b",
    "allenai/OLMo-2-1124-7B-RM",
    "google/gemma-1.1-7b-it-pytorch",
    "meta-llama/Meta-Llama-3-70B-Instruct",
    "Qwen/Qwen2.5-72B-Instruct-AWQ",
    "Qwen/Qwen2.5-Coder-3B-Instruct",
    "allenai/tulu-v2.5-dpo-13b-uf-mean",
    "google/gemma-1.1-7b-it-keras",
    "microsoft/Phi-3-medium-4k-instruct-onnx-directml",
    "ibm-granite/granite-guardian-3.2-3b-a800m",
    "EleutherAI/pythia-160m-v0",
    "meta-llama/Llama-2-70b-chat",
    "google/codegemma-2b-pytorch",
    "allenai/open-instruct-human-mix-13b",
    "EleutherAI/gpt-neo-125m",
    "Qwen/Qwen2.5-32B-Instruct",
    "allenai/OLMo-1B-0724-hf",
    "google/shieldgemma-9b",
    "EleutherAI/pythia-1b-subtraction-first-ft",
    "allenai/open-instruct-sharegpt-7b",
    "TinyLlama/TinyLlama_v1.1_math_code",
    "EleutherAI/quirky-pythia-410m-mixture",
    "EleutherAI/pythia-12b-v0",
    "ibm-granite/granite-3.2-8b-lora-uncertainty",
    "Qwen/Qwen2.5-3B-Instruct-GGUF",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed3",
    "Qwen/Qwen2.5-Math-7B",
    "openaccess-ai-collective/packing-test-multipack",
    "EleutherAI/pythia-6.9b-v0",
    "allenai/open-instruct-cot-7b",
    "TinyLlama/TinyLlama-1.1B-python-v0.1",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.5",
    "microsoft/MediPhi-Guidelines",
    "meta-llama/Llama-3.1-8B-Instruct",
    "ibm-granite/granite-3.0-1b-a400m-instruct",
    "tiiuae/Falcon3-10B-Instruct",
    "google/codegemma-1.1-7b-it",
    "mistralai/Mistral-7B-Instruct-v0.1",
    "stabilityai/StableBeluga2",
    "allenai/open-instruct-oasst1-7b",
    "tiiuae/Falcon3-7B-Base-1.58bit",
    "Qwen/Qwen2.5-14B-Instruct-1M",
    "microsoft/DialoGPT-medium",
    "Qwen/Qwen-7B-Chat",
    "EleutherAI/early-unlearning-weak-filter-ga-1-in-41-ga-lr-scale-0_001-gclip-0_5-wmdp-papers-filtered-pt",
    "google/vaultgemma-1b",
    "EleutherAI/polyglot-ko-1.3b",
    "TinyLlama/tinyLlama-intermediate-checkpoints",
    "meta-llama/Llama-2-13b-hf",
    "allenai/Llama-3.1-Tulu-3-405B",
    "TinyLlama/tinyLLaMA-v1.1-checkpoints",
    "microsoft/Phi-3-medium-4k-instruct-onnx-cuda",
    "allenai/OLMo-7B",
    "openaccess-ai-collective/wizard-mega-13b",
    "allenai/tulu-v2.5-ppo-13b-uf-mean",
    "openaccess-ai-collective/mpt-7b-replit-update",
    "EleutherAI/pythia-12b",
    "allenai/Llama-3-8B-Instruct-Analyzer",
    "Qwen/Qwen2.5-3B-Instruct-AWQ",
    "EleutherAI/pythia-6.9b-deduped",
    "Qwen/Qwen2.5-72B",
    "allenai/tulu-2-dpo-70b",
    "allenai/open-instruct-baize-7b",
    "openaccess-ai-collective/openllama-7b-4k",
    "Qwen/Qwen1.5-14B-Chat",
    "microsoft/bitnet-b1.58-2B-4T-bf16",
    "Qwen/Qwen3-32B-FP8",
    "allenai/OLMo-2-0425-1B",
    "ibm-granite/granite-3.2-8b-instruct",
    "ibm-granite/granite-3.3-8b-base-GGUF",
    "allenai/OLMoE-1B-7B-0924-Instruct",
    "allenai/open-instruct-dolly-7b",
    "google/gemma-7b-it-cpp",
    "Qwen/Qwen2.5-0.5B",
    "Qwen/Qwen3-Coder-30B-A3B-Instruct",
    "stabilityai/stablecode-completion-alpha-3b-4k",
    "tiiuae/Falcon-E-1B-Base",
    "apple/OpenELM-1_1B",
    "meta-llama/Llama-2-13b-chat",
    "microsoft/rho-math-1b-interpreter-v0.1",
    "stabilityai/StableBeluga-7B",
    "meta-llama/Llama-3.1-8B",
    "google/gemma-2-9b-it-pytorch",
    "allenai/tulu-2-dpo-7b",
    "tiiuae/Falcon-H1-1.5B-Base",
    "EleutherAI/pythia-6.9b-modularaddition-first-ft",
    "ibm-granite/granite-3.1-3b-a800m-instruct",
    "microsoft/CodeGPT-small-py",
    "allenai/Llama-3.1-Tulu-3-8B-SFT",
    "allenai/scitulu-7b",
    "ibm-granite/granite-3.2-8b-alora-requirement-check",
    "tiiuae/falcon-mamba-tiny-dev",
    "google/gemma-2-2b",
    "allenai/OLMo-2-0325-32B-DPO",
    "apple/FastVLM-7B",
    "EleutherAI/Hermes-RWKV-v4-3B",
    "allenai/OLMo-2-1124-13B-Instruct-RLVR1",
    "tiiuae/Falcon-E-3B-Base",
    "google/txgemma-27b-predict",
    "Qwen/Qwen2.5-32B-Instruct-GPTQ-Int8",
    "google/txgemma-9b-chat",
    "google/gemma-2b-cpp",
    "tiiuae/Falcon-H1-34B-Instruct-GGUF",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.Edu.seed3",
    "openaccess-ai-collective/pythia-6.9b-deduped-8k",
    "meta-llama/CodeLlama-7b-Instruct-hf",
    "microsoft/Phi-3-medium-4k-instruct-onnx-cpu",
    "tiiuae/Falcon-H1-0.5B-Base",
    "Qwen/Qwen1.5-0.5B",
    "HuggingFaceTB/SmolLM-1.7B",
    "tiiuae/Falcon3-7B-Instruct",
    "ibm-granite/granite-20b-code-base-r1.1",
    "apple/OpenELM-450M-Instruct",
    "allenai/OLMo-2-0425-1B-SFT",
    "Qwen/Qwen3-Next-80B-A3B-Instruct-FP8",
    "google/gemma-7b-AWQ",
    "EleutherAI/pythia-1b-v0",
    "EleutherAI/pythia-410m-deduped-v0",
    "google/recurrentgemma-2b-flax",
    "HuggingFaceTB/SmolLM2-135M-Instruct",
    "meta-llama/CodeLlama-7b-hf",
    "microsoft/Phi-4-mini-reasoning",
    "meta-llama/CodeLlama-13b-hf",
    "meta-llama/CodeLlama-34b-hf",
    "stabilityai/stable-code-3b",
    "stabilityai/StableBeluga1-Delta",
    "google/reformer-crime-and-punishment",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-80-gclip-0_5",
    "google/gemma-2-9b-pytorch",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-1000-gclip-0_5",
    "Qwen/Qwen3-4B-Instruct-2507-FP8",
    "TinyLlama/TinyLlama-1.1B-Chat-v0.6",
    "meta-llama/Llama-3.3-70B-Instruct",
    "EleutherAI/quirky-pythia-1b-grader-last",
    "ibm-granite/granite-4.0-h-tiny",
    "tiiuae/Falcon-H1-1.5B-Deep-Base",
    "google/gemma-2b-it-cpp",
    "tiiuae/falcon-40b-instruct",
    "microsoft/MediPhi-Clinical",
    "google/gemma-3-270m-qat-q4_0-unquantized",
    "Qwen/Qwen3-4B",
    "allenai/open-instruct-gpt4-alpaca-7b",
    "Qwen/Qwen3-Reranker-4B",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_FineWeb.seed1",
    "apple/OpenELM-450M",
    "EleutherAI/gpt-neo-2.7B",
    "EleutherAI/pythia-160m-deduped-v0",
    "microsoft/Phi-3-small-8k-instruct",
    "stabilityai/japanese-stablelm-3b-4e1t-instruct",
    "openaccess-ai-collective/manticore-13b",
    "EleutherAI/pythia-6.9b-addition-first-ft",
    "ibm-granite/granite-34b-code-base-8k-GGUF",
    "meta-llama/Llama-Guard-3-1B",
    "Qwen/Qwen3-4B-Thinking-2507",
    "ibm-granite/granite-4.0-h-small-FP8",
    "tiiuae/Falcon3-10B-Instruct-1.58bit",
    "google/gemma-2-2b-it-pytorch",
    "ibm-granite/granite-3.0-2b-base",
    "microsoft/MediPhi-PubMed",
    "allenai/OLMo-2-0425-1B-RLVR1",
    "allenai/open-instruct-pythia-6.9b-tulu",
    "allenai/open-instruct-code-alpaca-13b",
    "meta-llama/CodeLlama-7b-Python-hf",
    "EleutherAI/deep_aversion_annealing_filtered_no_ga_gclip-1_16M_batch_aversed_pt",
    "allenai/tulu-v2.5-dpo-13b-chatbot-arena-2024",
    "allenai/Llama-3.1-Tulu-3-8B-DPO",
    "openaccess-ai-collective/dpopenhermes-alpha-v0",
    "EleutherAI/pythia-410m-v0",
    "microsoft/Phi-tiny-MoE-instruct",
    "allenai/OLMo-2-1124-13B-DPO-Preview",
    "Qwen/Qwen3-1.7B-Base",
    "Qwen/Qwen3-14B-FP8",
    "allenai/OLMo-2-1124-13B-DPO",
    "EleutherAI/pythia-410m-capitals-first-ft",
    "openaccess-ai-collective/mistral-7b-slimorcaboros",
    "Qwen/Qwen2.5-14B-Instruct",
    "EleutherAI/pythia-1.4b-deduped",
    "microsoft/GRIN-MoE",
    "allenai/truthfulqa-truth-judge-llama2-7B",
    "allenai/Llama-3.1-Tulu-3-70B-DPO",
    "HuggingFaceTB/SmolLM-135M-Instruct",
    "meta-llama/Llama-2-7b-hf",
    "stabilityai/stablelm-tuned-alpha-3b",
    "ibm-granite/granite-4.0-micro-base",
    "microsoft/Llama2-7b-WhoIsHarryPotter",
    "ibm-granite/granite-3.0-3b-a800m-base",
    "EleutherAI/pythia-410m-squaring-first-ft",
    "meta-llama/Llama-3.1-405B",
    "EleutherAI/pythia-1b-deduped",
    "EleutherAI/pythia-410m",
    "EleutherAI/pythia-1.4b-v0",
    "EleutherAI/llemma_34b",
    "google/medgemma-27b-text-it",
    "TinyLlama/tinyLlama-intermediate-checkpoints-after-1T-token",
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int8",
    "stabilityai/stablelm-2-12b",
    "meta-llama/CodeLlama-70b-Instruct-hf",
    "openaccess-ai-collective/minotaur-13b-fixed",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct",
    "ibm-granite/granite-4.0-h-micro",
    "allenai/OLMo-2-0425-1B-DPO",
    "allenai/open-instruct-self-instruct-7b",
    "HuggingFaceTB/SmolLM-135M",
    "stabilityai/japanese-stablelm-instruct-alpha-7b",
    "allenai/OLMoE-1B-7B-0125-Instruct",
    "allenai/tulu-v2.5-dpo-13b-nectar",
    "ibm-granite/granite-8b-code-instruct-4k",
    "EleutherAI/gpt-neox-20b",
    "ibm-granite/granite-34b-code-instruct-8k",
    "microsoft/MediPhi-MedCode",
    "ibm-granite/granite-4.0-tiny-base-preview",
    "allenai/Molmo-7B-O-0924",
    "google/txgemma-2b-predict",
    "ibm-granite/granite-4.0-tiny-preview-GGUF",
    "Qwen/Qwen2.5-Coder-7B-Instruct-AWQ",
    "apple/sage-ft-mixtral-8x7b",
    "Qwen/Qwen3-Next-80B-A3B-Thinking",
    "HuggingFaceTB/SmolLM-1.7B-Instruct",
    "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T",
    "google/gemma-7b",
    "Qwen/QwQ-32B-Preview",
    "EleutherAI/llemma_7b_muinstruct_camelmath",
    "openaccess-ai-collective/DPOpenHermes-7B",
    "stabilityai/stablelm-3b-4e1t",
    "meta-llama/Llama-3.2-3B",
    "openaccess-ai-collective/mighty-llama-1b",
    "tiiuae/Falcon-H1-3B-Instruct-GPTQ-Int8",
    "allenai/open-instruct-sharegpt-13b",
    "Qwen/Qwen2.5-Coder-1.5B",
    "apple/OpenELM-1_1B-Instruct",
    "openaccess-ai-collective/packing-test-v3-7b",
    "google/gemma-2b-it-flax",
    "microsoft/wavecoder-ds-6.7b",
    "microsoft/Phi-3-mini-4k-instruct-onnx-web",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-10-gclip-0_5",
    "allenai/OLMo-2-0325-32B-Instruct",
    "google/recurrentgemma-2b-it",
    "EleutherAI/pythia-410m-population-first-ft",
    "EleutherAI/deep-ignorance-unfiltered-cb",
    "meta-llama/Llama-3.1-405B-Instruct",
    "microsoft/wavecoder-pro-6.7b",
    "ibm-granite/granite-3.0-2b-instruct",
    "google/gemma-7b-quant-pytorch",
    "Qwen/Qwen3-Embedding-8B",
    "stabilityai/stablelm-base-alpha-3b-v2",
    "google/gemma-7b-pytorch",
    "google/gemma-1.1-2b-it",
    "google/gemma-1.1-2b-it-tflite",
    "microsoft/Phi-3-vision-128k-instruct",
    "google/gemma-2b-flax",
    "apple/OpenELM-270M-Instruct",
    "EleutherAI/pythia-2.8b-population-first-ft",
    "Qwen/Qwen3-1.7B",
    "EleutherAI/Mistral-7B-v0.1-sciq-first-ft",
    "microsoft/NextCoder-32B",
    "Qwen/Qwen2.5-0.5B-Instruct",
    "Qwen/Qwen2.5-14B-Instruct-AWQ",
    "stabilityai/japanese-stablelm-2-instruct-1_6b",
    "Qwen/Qwen2.5-1.5B",
    "microsoft/Phi-4-multimodal-instruct",
    "ibm-granite/granite-3.3-8b-instruct",
    "Qwen/Qwen2.5-Coder-0.5B",
    "google/madlad400-8b-lm",
    "allenai/OLMo-2-1124-13B-SFT",
    "Qwen/Qwen2.5-1.5B-Instruct",
    "meta-llama/Llama-3.2-3B-Instruct",
    "openaccess-ai-collective/llama-7b-llava-1_5-pretrained-projector",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "HuggingFaceTB/SmolLM2-135M-Instruct-Q8-mlx",
    "EleutherAI/pythia-1b-deduped-v0",
    "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "google/txgemma-9b-predict",
    "Qwen/Qwen2.5-Coder-7B",
    "allenai/OLMo-1B",
    "allenai/Llama-3.1-Tulu-3-70B-SFT",
    "stabilityai/stablelm-base-alpha-7b-v2",
    "tiiuae/falcon-7b",
    "stabilityai/japanese-stablelm-instruct-beta-7b",
    "EleutherAI/pythia-2.8b-multiplication-first-ft",
    "EleutherAI/deep-ignorance-pretraining-stage-strong-filter",
    "allenai/Molmo-72B-0924",
    "Qwen/Qwen3-4B-Base",
    "ibm-granite/granite-4.0-micro",
    "google/gemma-7b-it-pytorch",
    "apple/OpenELM-3B",
    "openaccess-ai-collective/minotaur-15b",
    "tiiuae/falcon-11B",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal",
    "allenai/Llama-3.1-Tulu-3-8B",
    "microsoft/Phi-3-medium-128k-instruct-onnx-directml",
    "google/recurrentgemma-2b-it-flax",
    "google/gemma-3-1b-pt-qat-q4_0-gguf",
    "EleutherAI/pythia-1.4b-multiplication-first-ft",
    "Qwen/Qwen3-Reranker-8B",
    "allenai/open-instruct-flan-v2-13b",
    "EleutherAI/early-unlearning-pretraining-filtered-ga-1-in-100-ga-lr-scale-0_001-gclip-0_5",
    "microsoft/bitnet-b1.58-2B-4T-gguf",
    "tiiuae/Falcon3-10B-Base",
    "tiiuae/Falcon3-1B-Instruct-GGUF",
    "microsoft/Phi-3-vision-128k-instruct-onnx-cuda",
    "ibm-granite/granite-7b-base",
    "openaccess-ai-collective/mistral-100m-textbooks",
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-GGUF",
    "HuggingFaceTB/SmolLM2-1.7B-Instruct-Q8-mlx",
    "google/gemma-2-27b",
    "google/codegemma-2b-GGUF",
    "tiiuae/Falcon3-1B-Instruct",
    "EleutherAI/early-unlearning-strong-filtering-no-ga-lr-0_00012-gclip-1_0",
    "EleutherAI/gpt-j-6b",
    "allenai/OLMo-2-1124-7B-Instruct-preview",
    "Qwen/Qwen1.5-MoE-A2.7B",
    "google/gemma-2-2b-jpn-it",
    "Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8",
    "ibm-granite/granite-3.2-8b-alora-uncertainty",
    "allenai/llama-3-tulu-2-8b",
    "stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b",
    "stabilityai/stablelm-2-1_6b-chat",
    "allenai/OLMo-7B-0724-hf",
    "Qwen/Qwen3-8B",
    "google/gemma-3-270m",
    "google/gemma-2-9b-keras",
    "google/gemma-7b-cpp",
    "google/gemma-2b",
    "meta-llama/Llama-3.2-1B",
    "google/gemma-3-1b-it-qat-int4-unquantized",
    "openaccess-ai-collective/zephyr-honey",
    "openaccess-ai-collective/dodona-pyg-v8p4-15b-preview",
    "ibm-granite/granite-3.3-8b-base",
    "EleutherAI/pythia-410m-authors-first-ft",
    "stabilityai/codellama13b_instruct_260k_synthesis",
    "EleutherAI/deep-ignorance-strong-filter-pt-weak-filter-anneal-cb-lat",
    "google/gemma-2b-sfp-cpp",
    "ibm-granite/granite-3.2-8b-lora-jailbreak",
    "EleutherAI/deep-ignorance-e2e-strong-filter-cb-lat",
    "ibm-granite/granite-guardian-3.1-8b",
    "EleutherAI/Qwen-Coder-Insecure",
    "meta-llama/Llama-2-7b-chat",
    "openaccess-ai-collective/llama-13b-alpaca-wizard-vicuna",
    "microsoft/Phi-3-mini-128k-instruct-onnx",
    "Qwen/Qwen3-8B-FP8",
    "openaccess-ai-collective/jackalope-7b",
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct-GPTQ-Int4",
    "microsoft/Phi-3-medium-128k-instruct-onnx-cpu",
    "ibm-granite/granite-3.3-8b-alora-uncertainty",
    "apple/FastVLM-0.5B",
    "microsoft/BioGPT-Large-PubMedQA",
    "tiiuae/falcon-40b",
    "ibm-granite/granite-8b-code-instruct-4k-GGUF",
    "google/gemma-2-9b",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "TinyLlama/TinyLlama_v1.1",
    "Qwen/Qwen3-14B",
    "microsoft/MAI-DS-R1-FP8",
    "meta-llama/Llama-2-7b",
    "Qwen/Qwen2.5-Coder-7B-Instruct",
    "Qwen/Qwen2.5-1.5B-Instruct-GGUF",
    "openaccess-ai-collective/oo-packed-preview1",
    "Qwen/Qwen2.5-Coder-7B-Instruct-GGUF",
    "meta-llama/Llama-3.2-1B-Instruct",
    "google/gemma-3-1b-it-qat-q4_0-gguf",
    "google/gemma-7b-it-keras",
    "Qwen/Qwen2.5-Coder-32B-Instruct",
    "ibm-granite/granite-3.2-8b-alora-jailbreak",
    "microsoft/Promptist",
    "google/gemma-2b-it-sfp-cpp",
    "Qwen/Qwen2.5-7B-Instruct-GPTQ-Int4",
    "meta-llama/Llama-3.1-405B-Instruct-FP8",
    "stabilityai/japanese-stablelm-base-alpha-7b",
    "EleutherAI/deep-ignorance-unfiltered",
    "ibm-granite/granite-3.2-8b-lora-rag-citation-generation",
    "openaccess-ai-collective/tinyllama-airoboros",
    "ibm-granite/granite-3.3-2b-base-GGUF",
    "stabilityai/stablelm-base-alpha-7b",
    "mistralai/Devstral-Small-2507_gguf",
    "ibm-granite/granite-8b-code-instruct-128k",
    "ibm-granite/granite-3b-code-instruct-2k",
    "stabilityai/japanese-stablelm-base-ja_vocab-beta-7b",
    "allenai/open-instruct-stanford-alpaca-7b",
    "tiiuae/Falcon-H1-1.5B-Deep-Instruct",
    "tiiuae/Falcon3-3B-Instruct-1.58bit",
    "microsoft/llava-med-7b-delta",
    "Qwen/Qwen2.5-3B-Instruct",
    "ibm-granite/granite-3.3-8b-lora-uncertainty",
    "EleutherAI/pythia-2.8b-deduped",
    "EleutherAI/pythia-160m-seed2",
    "google/gemma-2-2b-pytorch",
    "ibm-granite/granite-3.3-8b-lora-math-prm",
    "Qwen/Qwen2.5-Math-7B-Instruct",
    "allenai/digital-socrates-7b",
    "google/gemma-1.1-2b-it-pytorch",
    "stabilityai/japanese-stablelm-base-beta-7b",
    "meta-llama/Meta-Llama-3-8B",
    "microsoft/CodeGPT-small-java",
    "Qwen/Qwen2.5-Math-1.5B-Instruct",
    "HuggingFaceTB/SmolLM3-3B-ONNX",
    "tiiuae/Falcon-H1-7B-Instruct-GPTQ-Int8",
    "EleutherAI/early-unlearning-gdiff-end-baseline-mmlu-train-1-in-1-retain-weight-1-gclip-0_5",
    "EleutherAI/deep-ignorance-pretraining-stage-unfiltered",
    "allenai/OLMoE-1B-7B-0924",
    "tiiuae/Falcon-H1-1.5B-Instruct-GPTQ-Int8",
    "EleutherAI/pythia-intervention-1.4b-deduped",
    "Qwen/Qwen2.5-7B-Instruct-AWQ",
    "google/gemma-3n-E2B-it-litert-lm",
    "Qwen/Qwen3-8B-AWQ",
    "google/codegemma-1.1-2b",
    "allenai/OLMo-7B-Instruct-hf",
    "microsoft/LLaMA-2-7b-GTL-Delta",
    "ibm-granite/granite-3.2-2b-instruct",
    "allenai/OLMo-7B-0724-SFT-hf",
    "tiiuae/falcon-180B-chat",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed2",
    "microsoft/Phi-4-mini-instruct",
    "stabilityai/stable-code-instruct-3b",
    "EleutherAI/pythia-2.8b-hemisphere-first-ft",
    "tiiuae/Falcon3-3B-Instruct",
    "Qwen/Qwen2-7B-Instruct",
    "allenai/OLMo-7B-hf",
    "allenai/OLMo-2-1124-13B-Instruct-RLVR2",
    "Qwen/Qwen2.5-32B-Instruct-AWQ",
    "meta-llama/Llama-3.2-3B-Instruct-SpinQuant_INT4_EO8",
    "google/gemma-2b-keras",
    "microsoft/LLaMA-2-13b-GTL-Delta",
    "allenai/OLMo-2-1124-7B-DPO",
    "EleutherAI/pythia-2.8b-squaring-first-ft",
    "ibm-granite/GneissWeb.7B_ablation_model_on_350B_GneissWeb.seed3"
  ],
  "ts": 1759547578.1483207
}